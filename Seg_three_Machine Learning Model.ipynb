{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "from path import Path\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from collections import defaultdict\n",
    "import pickle, os\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary data preprocessing\n",
    "Original Dataset was provided by a Kaggle Project.  For the intial analysis of the dataset the information was imported to a local directory and then imported read into this jupyter notebook.  Later we will have the connection to the database here. The dataset already came as a csv file so no further processing was necessary.  \n",
    "\n",
    "Merging of the weather data was accomplished by using the World Weather Online API.  The download of the required information was achieved in a seperate jupyter notebook.  Data was formated as a simple csv file and was imported below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Flights for 2019:  565963   Total Flights for 2020:  599268\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>OP_CARRIER_AIRLINE_ID</th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN_AIRPORT_ID</th>\n",
       "      <th>ORIGIN_AIRPORT_SEQ_ID</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST_AIRPORT_ID</th>\n",
       "      <th>DEST_AIRPORT_SEQ_ID</th>\n",
       "      <th>DEST</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DEL15</th>\n",
       "      <th>DEP_TIME_BLK</th>\n",
       "      <th>ARR_TIME</th>\n",
       "      <th>ARR_DEL15</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>DISTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20363</td>\n",
       "      <td>9E</td>\n",
       "      <td>N8688C</td>\n",
       "      <td>3280</td>\n",
       "      <td>11953</td>\n",
       "      <td>1195302</td>\n",
       "      <td>GNV</td>\n",
       "      <td>10397</td>\n",
       "      <td>1039707</td>\n",
       "      <td>ATL</td>\n",
       "      <td>601.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0600-0659</td>\n",
       "      <td>722.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20363</td>\n",
       "      <td>9E</td>\n",
       "      <td>N348PQ</td>\n",
       "      <td>3281</td>\n",
       "      <td>13487</td>\n",
       "      <td>1348702</td>\n",
       "      <td>MSP</td>\n",
       "      <td>11193</td>\n",
       "      <td>1119302</td>\n",
       "      <td>CVG</td>\n",
       "      <td>1359.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1400-1459</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20363</td>\n",
       "      <td>9E</td>\n",
       "      <td>N8896A</td>\n",
       "      <td>3282</td>\n",
       "      <td>11433</td>\n",
       "      <td>1143302</td>\n",
       "      <td>DTW</td>\n",
       "      <td>11193</td>\n",
       "      <td>1119302</td>\n",
       "      <td>CVG</td>\n",
       "      <td>1215.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1200-1259</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20363</td>\n",
       "      <td>9E</td>\n",
       "      <td>N8886A</td>\n",
       "      <td>3283</td>\n",
       "      <td>15249</td>\n",
       "      <td>1524906</td>\n",
       "      <td>TLH</td>\n",
       "      <td>10397</td>\n",
       "      <td>1039707</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1521.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500-1559</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20363</td>\n",
       "      <td>9E</td>\n",
       "      <td>N8974C</td>\n",
       "      <td>3284</td>\n",
       "      <td>10397</td>\n",
       "      <td>1039707</td>\n",
       "      <td>ATL</td>\n",
       "      <td>11778</td>\n",
       "      <td>1177801</td>\n",
       "      <td>FSM</td>\n",
       "      <td>1847.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1900-1959</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DAY_OF_MONTH  DAY_OF_WEEK  OP_CARRIER_AIRLINE_ID OP_CARRIER TAIL_NUM  \\\n",
       "0             1            2                  20363         9E   N8688C   \n",
       "1             1            2                  20363         9E   N348PQ   \n",
       "2             1            2                  20363         9E   N8896A   \n",
       "3             1            2                  20363         9E   N8886A   \n",
       "4             1            2                  20363         9E   N8974C   \n",
       "\n",
       "   OP_CARRIER_FL_NUM  ORIGIN_AIRPORT_ID  ORIGIN_AIRPORT_SEQ_ID ORIGIN  \\\n",
       "0               3280              11953                1195302    GNV   \n",
       "1               3281              13487                1348702    MSP   \n",
       "2               3282              11433                1143302    DTW   \n",
       "3               3283              15249                1524906    TLH   \n",
       "4               3284              10397                1039707    ATL   \n",
       "\n",
       "   DEST_AIRPORT_ID  DEST_AIRPORT_SEQ_ID DEST  DEP_TIME  DEP_DEL15  \\\n",
       "0            10397              1039707  ATL     601.0        0.0   \n",
       "1            11193              1119302  CVG    1359.0        0.0   \n",
       "2            11193              1119302  CVG    1215.0        0.0   \n",
       "3            10397              1039707  ATL    1521.0        0.0   \n",
       "4            11778              1177801  FSM    1847.0        0.0   \n",
       "\n",
       "  DEP_TIME_BLK  ARR_TIME  ARR_DEL15  CANCELLED  DIVERTED  DISTANCE  \n",
       "0    0600-0659     722.0        0.0          0         0       300  \n",
       "1    1400-1459    1633.0        0.0          0         0       596  \n",
       "2    1200-1259    1329.0        0.0          0         0       229  \n",
       "3    1500-1559    1625.0        0.0          0         0       223  \n",
       "4    1900-1959    1940.0        0.0          0         0       579  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import testing dataset\n",
    "flights_2019 = pd.read_csv('Database/Data/jan_19_clean.csv')\n",
    "flights_2020 = pd.read_csv('Database/Data/jan_20_clean.csv')\n",
    "\n",
    "print('Total Flights for 2019: ', len(flights_2019)\n",
    "      , '  Total Flights for 2020: ', len(flights_2020) )\n",
    "\n",
    "flights_2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2019['Year'] = 2019\n",
    "flights_2020['Year'] = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flights_2020.ORIGIN.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>date_time</th>\n",
       "      <th>precipMM</th>\n",
       "      <th>visibility</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>windspeedKmph</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>islip,ny</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>8.5</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>islip,ny</td>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>12</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>islip,ny</td>\n",
       "      <td>2019-01-01 02:00:00</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>islip,ny</td>\n",
       "      <td>2019-01-01 03:00:00</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>18</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>islip,ny</td>\n",
       "      <td>2019-01-01 04:00:00</td>\n",
       "      <td>2.9</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>20</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   location            date_time  precipMM  visibility  cloudcover  \\\n",
       "0  islip,ny  2019-01-01 00:00:00       8.5           5         100   \n",
       "1  islip,ny  2019-01-01 01:00:00       4.3           5         100   \n",
       "2  islip,ny  2019-01-01 02:00:00       4.3           6         100   \n",
       "3  islip,ny  2019-01-01 03:00:00       5.8           6         100   \n",
       "4  islip,ny  2019-01-01 04:00:00       2.9           7          98   \n",
       "\n",
       "   windspeedKmph  humidity  \n",
       "0             10        91  \n",
       "1             12        93  \n",
       "2             15        94  \n",
       "3             18        96  \n",
       "4             20        96  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Weather Data\n",
    "weather_2018 = pd.read_csv('Database/weather/weather_data/weather_2019_df.csv')\n",
    "weather_2019 = pd.read_csv('Database/weather/weather_data/weather_2019_df.csv')\n",
    "weather_2020 = pd.read_csv('Database/weather/weather_data/weather_2020_df.csv')\n",
    "\n",
    "# Combine the weather dataframes\n",
    "weather_df = pd.concat([weather_2018, weather_2019, weather_2020])\n",
    "\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weather_df.location.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "709776"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABR</td>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABI</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADK</td>\n",
       "      <td>Adak Island</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAK</td>\n",
       "      <td>Akron/Canton</td>\n",
       "      <td>OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALB</td>\n",
       "      <td>Albany</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ORIGIN          CITY STATE\n",
       "0    ABR      Aberdeen    SD\n",
       "1    ABI       Abilene    TX\n",
       "2    ADK   Adak Island    AK\n",
       "3    CAK  Akron/Canton    OH\n",
       "4    ALB        Albany    NY"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import airport city information\n",
    "city_lookup_df = pd.read_csv(\"Database/Data/airport_codes.csv\")\n",
    "lookup_columns = list(city_lookup_df.columns)\n",
    "city_lookup_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_lookup_df.CITY = city_lookup_df.CITY.str.replace(\"-\", \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "city_lookup_df['Primary_City'] = city_lookup_df.CITY.str.split('/', expand=True)[0].str.replace('None', \"\")\n",
    "city_lookup_df['Secondary_City'] = city_lookup_df.CITY.str.split('/', expand=True)[1].str.replace('None', \"\")\n",
    "city_lookup_df['Tertiary_City'] = city_lookup_df.CITY.str.split('/', expand=True)[2].str.replace('None', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>Primary_City</th>\n",
       "      <th>Secondary_City</th>\n",
       "      <th>Tertiary_City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABR</td>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>SD</td>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABI</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADK</td>\n",
       "      <td>Adak Island</td>\n",
       "      <td>AK</td>\n",
       "      <td>Adak Island</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAK</td>\n",
       "      <td>Akron/Canton</td>\n",
       "      <td>OH</td>\n",
       "      <td>Akron</td>\n",
       "      <td>Canton</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALB</td>\n",
       "      <td>Albany</td>\n",
       "      <td>NY</td>\n",
       "      <td>Albany</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ORIGIN          CITY STATE Primary_City Secondary_City Tertiary_City\n",
       "0    ABR      Aberdeen    SD     Aberdeen           None          None\n",
       "1    ABI       Abilene    TX      Abilene           None          None\n",
       "2    ADK   Adak Island    AK  Adak Island           None          None\n",
       "3    CAK  Akron/Canton    OH        Akron         Canton          None\n",
       "4    ALB        Albany    NY       Albany           None          None"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_lookup_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>Primary_City</th>\n",
       "      <th>Secondary_City</th>\n",
       "      <th>Tertiary_City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAK</td>\n",
       "      <td>Akron/Canton</td>\n",
       "      <td>OH</td>\n",
       "      <td>Akron</td>\n",
       "      <td>Canton</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ABE</td>\n",
       "      <td>Allentown/Bethlehem/Easton</td>\n",
       "      <td>PA</td>\n",
       "      <td>Allentown</td>\n",
       "      <td>Bethlehem</td>\n",
       "      <td>Easton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ACV</td>\n",
       "      <td>Eureka/Arcata</td>\n",
       "      <td>CA</td>\n",
       "      <td>Eureka</td>\n",
       "      <td>Arcata</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AVL</td>\n",
       "      <td>Asheville/Hendersonville</td>\n",
       "      <td>NC</td>\n",
       "      <td>Asheville</td>\n",
       "      <td>Hendersonville</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MBS</td>\n",
       "      <td>Bay City/Midland/Saginaw</td>\n",
       "      <td>MI</td>\n",
       "      <td>Bay City</td>\n",
       "      <td>Midland</td>\n",
       "      <td>Saginaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BPT</td>\n",
       "      <td>Beaumont/Port Arthur</td>\n",
       "      <td>TX</td>\n",
       "      <td>Beaumont</td>\n",
       "      <td>Port Arthur</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>GPT</td>\n",
       "      <td>Biloxi/Gulfport</td>\n",
       "      <td>MS</td>\n",
       "      <td>Biloxi</td>\n",
       "      <td>Gulfport</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BGM</td>\n",
       "      <td>Binghamton/Endicott/Johnson City</td>\n",
       "      <td>NY</td>\n",
       "      <td>Binghamton</td>\n",
       "      <td>Endicott</td>\n",
       "      <td>Johnson City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>MRY</td>\n",
       "      <td>Carmel/Monterey</td>\n",
       "      <td>CA</td>\n",
       "      <td>Carmel</td>\n",
       "      <td>Monterey</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>CMI</td>\n",
       "      <td>Champaign/Urbana</td>\n",
       "      <td>IL</td>\n",
       "      <td>Champaign</td>\n",
       "      <td>Urbana</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>MDW</td>\n",
       "      <td>Chicago / Midway</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Midway</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago / O'Hare</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>O'Hare</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>HIB</td>\n",
       "      <td>Chisholm/Hibbing</td>\n",
       "      <td>MN</td>\n",
       "      <td>Chisholm</td>\n",
       "      <td>Hibbing</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>PIE</td>\n",
       "      <td>Clearwater/St Petersburg</td>\n",
       "      <td>FL</td>\n",
       "      <td>Clearwater</td>\n",
       "      <td>St Petersburg</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>COD</td>\n",
       "      <td>Cody/Yellowstone</td>\n",
       "      <td>WY</td>\n",
       "      <td>Cody</td>\n",
       "      <td>Yellowstone</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>DFW</td>\n",
       "      <td>Dallas/Fort Worth</td>\n",
       "      <td>TX</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>Fort Worth</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>RDU</td>\n",
       "      <td>Raleigh/Durham</td>\n",
       "      <td>NC</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Durham</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>VPS</td>\n",
       "      <td>Fort Walton Beach/Valparaiso</td>\n",
       "      <td>FL</td>\n",
       "      <td>Fort Walton Beach</td>\n",
       "      <td>Valparaiso</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>GGG</td>\n",
       "      <td>Gladewater/Kilgore/Longview</td>\n",
       "      <td>TX</td>\n",
       "      <td>Gladewater</td>\n",
       "      <td>Kilgore</td>\n",
       "      <td>Longview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>GSO</td>\n",
       "      <td>Greensboro/High Point</td>\n",
       "      <td>NC</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>High Point</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>GSP</td>\n",
       "      <td>Greenville/Spartanburg</td>\n",
       "      <td>SC</td>\n",
       "      <td>Greenville</td>\n",
       "      <td>Spartanburg</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>SUN</td>\n",
       "      <td>Hailey/Sun Valley</td>\n",
       "      <td>ID</td>\n",
       "      <td>Hailey</td>\n",
       "      <td>Sun Valley</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>PHF</td>\n",
       "      <td>Hampton/Williamsburg</td>\n",
       "      <td>VA</td>\n",
       "      <td>Hampton</td>\n",
       "      <td>Williamsburg</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>BDL</td>\n",
       "      <td>Hartford/Windsor Locks</td>\n",
       "      <td>CT</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>Windsor Locks</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>ITO</td>\n",
       "      <td>Hilo / Island of Hawaii</td>\n",
       "      <td>HI</td>\n",
       "      <td>Hilo</td>\n",
       "      <td>Island of Hawaii</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>HNL</td>\n",
       "      <td>Honolulu / Island of Oahu</td>\n",
       "      <td>HI</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>Island of Oahu</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>HOU</td>\n",
       "      <td>Houston / Hobby</td>\n",
       "      <td>TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Hobby</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>IAH</td>\n",
       "      <td>Houston / George Bush Intercontinental</td>\n",
       "      <td>TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>George Bush Intercontinental</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>OGG</td>\n",
       "      <td>Kahului/ Island of Maui</td>\n",
       "      <td>HI</td>\n",
       "      <td>Kahului</td>\n",
       "      <td>Island of Maui</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>LIH</td>\n",
       "      <td>Lihue / Island of Kaui</td>\n",
       "      <td>HI</td>\n",
       "      <td>Lihue</td>\n",
       "      <td>Island of Kaui</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>KOA</td>\n",
       "      <td>Kona / Island of Hawaii</td>\n",
       "      <td>HI</td>\n",
       "      <td>Kona</td>\n",
       "      <td>Island of Hawaii</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>MFE</td>\n",
       "      <td>Mcallen/Mission</td>\n",
       "      <td>TX</td>\n",
       "      <td>Mcallen</td>\n",
       "      <td>Mission</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>MAF</td>\n",
       "      <td>Midland/Odessa</td>\n",
       "      <td>TX</td>\n",
       "      <td>Midland</td>\n",
       "      <td>Odessa</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>JFK</td>\n",
       "      <td>New York / Kennedy</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>LGA</td>\n",
       "      <td>New York / La Guardia</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>La Guardia</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>SWF</td>\n",
       "      <td>Newburgh/Stewart Field</td>\n",
       "      <td>NY</td>\n",
       "      <td>Newburgh</td>\n",
       "      <td>Stewart Field</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>SNA</td>\n",
       "      <td>Orange County/Santa Ana</td>\n",
       "      <td>CA</td>\n",
       "      <td>Orange County</td>\n",
       "      <td>Santa Ana</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>TTN</td>\n",
       "      <td>Trenton/Mercer</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Trenton</td>\n",
       "      <td>Mercer</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>SCC</td>\n",
       "      <td>Prudhoe Bay/Deadhorse</td>\n",
       "      <td>AK</td>\n",
       "      <td>Prudhoe Bay</td>\n",
       "      <td>Deadhorse</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>AVP</td>\n",
       "      <td>Scranton/Wilkes Barre</td>\n",
       "      <td>PA</td>\n",
       "      <td>Scranton</td>\n",
       "      <td>Wilkes Barre</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>SEA</td>\n",
       "      <td>Seattle/Tacoma</td>\n",
       "      <td>WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>Tacoma</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>SCE</td>\n",
       "      <td>State College/University Park</td>\n",
       "      <td>PA</td>\n",
       "      <td>State College</td>\n",
       "      <td>University Park</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>CWA</td>\n",
       "      <td>Stevens Point/Wausau</td>\n",
       "      <td>WI</td>\n",
       "      <td>Stevens Point</td>\n",
       "      <td>Wausau</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>IAD</td>\n",
       "      <td>Washington / Dulles</td>\n",
       "      <td>DC</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Dulles</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>DCA</td>\n",
       "      <td>Washington / Reagan National</td>\n",
       "      <td>DC</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Reagan National</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ORIGIN                                    CITY STATE       Primary_City  \\\n",
       "3      CAK                            Akron/Canton    OH              Akron   \n",
       "7      ABE              Allentown/Bethlehem/Easton    PA          Allentown   \n",
       "12     ACV                           Eureka/Arcata    CA             Eureka   \n",
       "13     AVL                Asheville/Hendersonville    NC          Asheville   \n",
       "24     MBS                Bay City/Midland/Saginaw    MI           Bay City   \n",
       "25     BPT                    Beaumont/Port Arthur    TX           Beaumont   \n",
       "31     GPT                         Biloxi/Gulfport    MS             Biloxi   \n",
       "32     BGM        Binghamton/Endicott/Johnson City    NY         Binghamton   \n",
       "48     MRY                         Carmel/Monterey    CA             Carmel   \n",
       "52     CMI                        Champaign/Urbana    IL          Champaign   \n",
       "59     MDW                        Chicago / Midway    IL           Chicago    \n",
       "60     ORD                        Chicago / O'Hare    IL           Chicago    \n",
       "61     HIB                        Chisholm/Hibbing    MN           Chisholm   \n",
       "64     PIE                Clearwater/St Petersburg    FL         Clearwater   \n",
       "66     COD                        Cody/Yellowstone    WY               Cody   \n",
       "76     DFW                       Dallas/Fort Worth    TX             Dallas   \n",
       "87     RDU                          Raleigh/Durham    NC            Raleigh   \n",
       "105    VPS            Fort Walton Beach/Valparaiso    FL  Fort Walton Beach   \n",
       "111    GGG             Gladewater/Kilgore/Longview    TX         Gladewater   \n",
       "118    GSO                   Greensboro/High Point    NC         Greensboro   \n",
       "119    GSP                  Greenville/Spartanburg    SC         Greenville   \n",
       "122    SUN                       Hailey/Sun Valley    ID             Hailey   \n",
       "123    PHF                    Hampton/Williamsburg    VA            Hampton   \n",
       "127    BDL                  Hartford/Windsor Locks    CT           Hartford   \n",
       "131    ITO                 Hilo / Island of Hawaii    HI              Hilo    \n",
       "133    HNL               Honolulu / Island of Oahu    HI          Honolulu    \n",
       "134    HOU                         Houston / Hobby    TX           Houston    \n",
       "135    IAH  Houston / George Bush Intercontinental    TX           Houston    \n",
       "150    OGG                 Kahului/ Island of Maui    HI            Kahului   \n",
       "153    LIH                  Lihue / Island of Kaui    HI             Lihue    \n",
       "159    KOA                 Kona / Island of Hawaii    HI              Kona    \n",
       "185    MFE                         Mcallen/Mission    TX            Mcallen   \n",
       "191    MAF                          Midland/Odessa    TX            Midland   \n",
       "207    JFK                      New York / Kennedy    NY          New York    \n",
       "208    LGA                   New York / La Guardia    NY          New York    \n",
       "210    SWF                  Newburgh/Stewart Field    NY           Newburgh   \n",
       "220    SNA                 Orange County/Santa Ana    CA      Orange County   \n",
       "231    TTN                          Trenton/Mercer    NJ            Trenton   \n",
       "242    SCC                   Prudhoe Bay/Deadhorse    AK        Prudhoe Bay   \n",
       "278    AVP                   Scranton/Wilkes Barre    PA           Scranton   \n",
       "279    SEA                          Seattle/Tacoma    WA            Seattle   \n",
       "289    SCE           State College/University Park    PA      State College   \n",
       "291    CWA                    Stevens Point/Wausau    WI      Stevens Point   \n",
       "307    IAD                     Washington / Dulles    DC        Washington    \n",
       "308    DCA            Washington / Reagan National    DC        Washington    \n",
       "\n",
       "                    Secondary_City Tertiary_City  \n",
       "3                           Canton          None  \n",
       "7                        Bethlehem        Easton  \n",
       "12                          Arcata          None  \n",
       "13                  Hendersonville          None  \n",
       "24                         Midland       Saginaw  \n",
       "25                     Port Arthur          None  \n",
       "31                        Gulfport          None  \n",
       "32                        Endicott  Johnson City  \n",
       "48                        Monterey          None  \n",
       "52                          Urbana          None  \n",
       "59                          Midway          None  \n",
       "60                          O'Hare          None  \n",
       "61                         Hibbing          None  \n",
       "64                   St Petersburg          None  \n",
       "66                     Yellowstone          None  \n",
       "76                      Fort Worth          None  \n",
       "87                          Durham          None  \n",
       "105                     Valparaiso          None  \n",
       "111                        Kilgore      Longview  \n",
       "118                     High Point          None  \n",
       "119                    Spartanburg          None  \n",
       "122                     Sun Valley          None  \n",
       "123                   Williamsburg          None  \n",
       "127                  Windsor Locks          None  \n",
       "131               Island of Hawaii          None  \n",
       "133                 Island of Oahu          None  \n",
       "134                          Hobby          None  \n",
       "135   George Bush Intercontinental          None  \n",
       "150                 Island of Maui          None  \n",
       "153                 Island of Kaui          None  \n",
       "159               Island of Hawaii          None  \n",
       "185                        Mission          None  \n",
       "191                         Odessa          None  \n",
       "207                        Kennedy          None  \n",
       "208                     La Guardia          None  \n",
       "210                  Stewart Field          None  \n",
       "220                      Santa Ana          None  \n",
       "231                         Mercer          None  \n",
       "242                      Deadhorse          None  \n",
       "278                   Wilkes Barre          None  \n",
       "279                         Tacoma          None  \n",
       "289                University Park          None  \n",
       "291                         Wausau          None  \n",
       "307                         Dulles          None  \n",
       "308                Reagan National          None  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_lookup_df[city_lookup_df['Secondary_City'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('Primary_City', 'STATE')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ('Primary_City', 'STATE')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-149-e48294618d7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     location_lookup_df = location_lookup_df.append(\n\u001b[1;32m----> 8\u001b[1;33m         city_lookup_df[city_option, 'STATE'].apply(lambda row: ','.join(row.values.astype(str)), axis=1))\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ('Primary_City', 'STATE')"
     ]
    }
   ],
   "source": [
    "cities_option = ['Primary_City', 'Secondary_City', 'Tertiary_City']\n",
    "lookup_columns.append(\"locations\")\n",
    "\n",
    "location_lookup_df = pd.DataFrame(columns=lookup_columns) \n",
    "for city_option in cities_option:\n",
    "    x = city_lookup_df[city_lookup_df[city_option].notnull()]\n",
    "    \n",
    "    location_lookup_df = location_lookup_df.append(\n",
    "        x[[city_option, 'STATE']].apply(lambda row: ','.join(row.values.astype(str)), axis=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Additional_locations = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_lookup_df['location'] = city_lookup_df['location'].str.lower()\n",
    "city_lookup_df['location'] = city_lookup_df['location'].str.replace(\" \",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>Primary_City</th>\n",
       "      <th>Secondary_City</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABR</td>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>SD</td>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>None</td>\n",
       "      <td>aberdeen,sd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABI</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>None</td>\n",
       "      <td>abilene,tx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADK</td>\n",
       "      <td>Adak Island</td>\n",
       "      <td>AK</td>\n",
       "      <td>Adak Island</td>\n",
       "      <td>None</td>\n",
       "      <td>adakisland,ak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAK</td>\n",
       "      <td>Akron/Canton</td>\n",
       "      <td>OH</td>\n",
       "      <td>Akron</td>\n",
       "      <td>Canton</td>\n",
       "      <td>akron,oh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALB</td>\n",
       "      <td>Albany</td>\n",
       "      <td>NY</td>\n",
       "      <td>Albany</td>\n",
       "      <td>None</td>\n",
       "      <td>albany,ny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ORIGIN          CITY STATE Primary_City Secondary_City       location\n",
       "0    ABR      Aberdeen    SD     Aberdeen           None    aberdeen,sd\n",
       "1    ABI       Abilene    TX      Abilene           None     abilene,tx\n",
       "2    ADK   Adak Island    AK  Adak Island           None  adakisland,ak\n",
       "3    CAK  Akron/Canton    OH        Akron         Canton       akron,oh\n",
       "4    ALB        Albany    NY       Albany           None      albany,ny"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_lookup_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>date_time</th>\n",
       "      <th>precipMM</th>\n",
       "      <th>visibility</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>windspeedKmph</th>\n",
       "      <th>humidity</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>Primary_City</th>\n",
       "      <th>Secondary_City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>islip,ny</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>8.5</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>91</td>\n",
       "      <td>ISP</td>\n",
       "      <td>Islip</td>\n",
       "      <td>NY</td>\n",
       "      <td>Islip</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>islip,ny</td>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>12</td>\n",
       "      <td>93</td>\n",
       "      <td>ISP</td>\n",
       "      <td>Islip</td>\n",
       "      <td>NY</td>\n",
       "      <td>Islip</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>islip,ny</td>\n",
       "      <td>2019-01-01 02:00:00</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "      <td>94</td>\n",
       "      <td>ISP</td>\n",
       "      <td>Islip</td>\n",
       "      <td>NY</td>\n",
       "      <td>Islip</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>islip,ny</td>\n",
       "      <td>2019-01-01 03:00:00</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>18</td>\n",
       "      <td>96</td>\n",
       "      <td>ISP</td>\n",
       "      <td>Islip</td>\n",
       "      <td>NY</td>\n",
       "      <td>Islip</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>islip,ny</td>\n",
       "      <td>2019-01-01 04:00:00</td>\n",
       "      <td>2.9</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>20</td>\n",
       "      <td>96</td>\n",
       "      <td>ISP</td>\n",
       "      <td>Islip</td>\n",
       "      <td>NY</td>\n",
       "      <td>Islip</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   location            date_time  precipMM  visibility  cloudcover  \\\n",
       "0  islip,ny  2019-01-01 00:00:00       8.5           5         100   \n",
       "1  islip,ny  2019-01-01 01:00:00       4.3           5         100   \n",
       "2  islip,ny  2019-01-01 02:00:00       4.3           6         100   \n",
       "3  islip,ny  2019-01-01 03:00:00       5.8           6         100   \n",
       "4  islip,ny  2019-01-01 04:00:00       2.9           7          98   \n",
       "\n",
       "   windspeedKmph  humidity ORIGIN   CITY STATE Primary_City Secondary_City  \n",
       "0             10        91    ISP  Islip    NY        Islip           None  \n",
       "1             12        93    ISP  Islip    NY        Islip           None  \n",
       "2             15        94    ISP  Islip    NY        Islip           None  \n",
       "3             18        96    ISP  Islip    NY        Islip           None  \n",
       "4             20        96    ISP  Islip    NY        Islip           None  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_merged = pd.merge(weather_df, city_lookup_df, on = \"location\", how = \"left\")\n",
    "weather_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['saultstemarie,mi,', 'bristol,tn', 'saginaw,mi', 'gulfport,ms',\n",
       "       'deadhorse,ak', 'huntington,wv', 'rhinelander,wi,', 'monterey,ca',\n",
       "       'longview,tx', 'durham,nc', 'wausau,wi', 'yellowstone,wy',\n",
       "       'kauai,hi', 'fortworth,tx', 'universitypark,pa', 'easton,pa',\n",
       "       'odessa,tx', 'arcata,ca', 'maui,hi'], dtype=object)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_merged[weather_merged.ORIGIN.isnull()].location.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>Primary_City</th>\n",
       "      <th>Secondary_City</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>SFO</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>None</td>\n",
       "      <td>sanfrancisco,ca</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ORIGIN           CITY STATE   Primary_City Secondary_City         location\n",
       "266    SFO  San Francisco    CA  San Francisco           None  sanfrancisco,ca"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_lookup_df[city_lookup_df.CITY == \"San Francisco\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Feature Engineering\n",
    "Beyond a visual inspection of the head of the data the following steps were performed below:\n",
    "\n",
    "1) Determined if there are any rows that need to be dropped because they are missing data.\n",
    "\n",
    "2) Determine which columns of data will need to be included in the training set.\n",
    "\n",
    "3) Perform the inital encoding of the columns that contained objects as numerical values so it would be easier for the machine learning model to process it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows with missing information from 2019 data was:   0\n"
     ]
    }
   ],
   "source": [
    "na_count = flights_2019.DAY_OF_MONTH.count() - flights_2019.dropna(axis=0).DAY_OF_MONTH.count()\n",
    "print('Total rows with missing information from 2019 data was:  ', na_count )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows with missing information from 2019 data was:   0\n"
     ]
    }
   ],
   "source": [
    "na_count = flights_2020.DAY_OF_MONTH.count() - flights_2020.dropna(axis=0).DAY_OF_MONTH.count()\n",
    "print('Total rows with missing information from 2019 data was:  ', na_count )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step one complete.  The datasets are already cleaned with no missing information in any of the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two data sets to give more data for the model to work with\n",
    "flights = pd.concat([flights_2019, flights_2020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DAY_OF_MONTH', 'DAY_OF_WEEK', 'OP_CARRIER_AIRLINE_ID', 'OP_CARRIER',\n",
       "       'TAIL_NUM', 'OP_CARRIER_FL_NUM', 'ORIGIN_AIRPORT_ID',\n",
       "       'ORIGIN_AIRPORT_SEQ_ID', 'ORIGIN', 'DEST_AIRPORT_ID',\n",
       "       'DEST_AIRPORT_SEQ_ID', 'DEST', 'DEP_TIME', 'DEP_DEL15', 'DEP_TIME_BLK',\n",
       "       'ARR_TIME', 'ARR_DEL15', 'CANCELLED', 'DIVERTED', 'DISTANCE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Look at the available columns\n",
    "flights.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:\n",
    "#### Feature Selection:\n",
    "\n",
    "To determine which features to include it was important to determine how we want to use the predictive model.\n",
    "In this case we will be taking a set of inputs from the user and displaying which time slot is most likely to not\n",
    "have a flight delay. So we will only include information the model that we can get from the user or provide look up tables for.\n",
    "\n",
    "The filterdList below included all the data that we either we will be able to get from the user, will be a look up\n",
    "or is the primary feature we want to predict. \n",
    "\n",
    "In this case it is whether there will be a departure delay or not the column name DEP_DEL15 will the be feature we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>DEP_DEL15</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>DEP_TIME_BLK</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9E</td>\n",
       "      <td>GNV</td>\n",
       "      <td>ATL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "      <td>0600-0659</td>\n",
       "      <td>N8688C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9E</td>\n",
       "      <td>MSP</td>\n",
       "      <td>CVG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>596</td>\n",
       "      <td>1400-1459</td>\n",
       "      <td>N348PQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9E</td>\n",
       "      <td>DTW</td>\n",
       "      <td>CVG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229</td>\n",
       "      <td>1200-1259</td>\n",
       "      <td>N8896A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9E</td>\n",
       "      <td>TLH</td>\n",
       "      <td>ATL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223</td>\n",
       "      <td>1500-1559</td>\n",
       "      <td>N8886A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9E</td>\n",
       "      <td>ATL</td>\n",
       "      <td>FSM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>579</td>\n",
       "      <td>1900-1959</td>\n",
       "      <td>N8974C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DAY_OF_MONTH  DAY_OF_WEEK OP_CARRIER ORIGIN DEST  DEP_DEL15  DISTANCE  \\\n",
       "0             1            2         9E    GNV  ATL        0.0       300   \n",
       "1             1            2         9E    MSP  CVG        0.0       596   \n",
       "2             1            2         9E    DTW  CVG        0.0       229   \n",
       "3             1            2         9E    TLH  ATL        0.0       223   \n",
       "4             1            2         9E    ATL  FSM        0.0       579   \n",
       "\n",
       "  DEP_TIME_BLK TAIL_NUM  \n",
       "0    0600-0659   N8688C  \n",
       "1    1400-1459   N348PQ  \n",
       "2    1200-1259   N8896A  \n",
       "3    1500-1559   N8886A  \n",
       "4    1900-1959   N8974C  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the list that we are going to keep as features\n",
    "filteredList = ['DAY_OF_MONTH', 'DAY_OF_WEEK', 'OP_CARRIER', 'ORIGIN', 'DEST', 'DEP_DEL15', 'DISTANCE'\n",
    "                ,'DEP_TIME_BLK', 'TAIL_NUM']\n",
    "\n",
    "# Keep the list of columns that were removed...possibly for later use.\n",
    "columnsRemoved = ['OP_CARRIER_AIRLINE_ID', 'DEST_AIRPORT_SEQ_ID', 'ORIGIN_AIRPORT_SEQ_ID' , 'ORIGIN_AIRPORT_ID'\n",
    "                  , 'OP_CARRIER_FL_NUM', 'DEST_AIRPORT_ID', 'ARR_TIME', 'ARR_DEL15', 'CANCELLED', 'DIVERTED', 'DEP_TIME']\n",
    "\n",
    "# Filter the data to only include the columns we want\n",
    "machine_model_df = flights.filter(filteredList)\n",
    "machine_model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the feature we want to predict as a integer since on import it was made a float\n",
    "machine_model_df.DEP_DEL15 = machine_model_df.DEP_DEL15.astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are evaluating the impact of including Departure Time and a floating number in the dataset.\n",
    "# if it is there then make it an integer\n",
    "if \"DEP_TIME\" in machine_model_df.columns:\n",
    "    machine_model_df.DEP_TIME = machine_model_df.DEP_TIME.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAY_OF_MONTH     int64\n",
       "DAY_OF_WEEK      int64\n",
       "OP_CARRIER      object\n",
       "ORIGIN          object\n",
       "DEST            object\n",
       "DEP_DEL15        int32\n",
       "DISTANCE         int64\n",
       "DEP_TIME_BLK    object\n",
       "TAIL_NUM        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine features and determine how the various features will need to be encoded\n",
    "machine_model_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OP_CARRIER        17\n",
       "ORIGIN           353\n",
       "DEST             353\n",
       "DEP_TIME_BLK      19\n",
       "TAIL_NUM        5854\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate our categorical variable list\n",
    "flights_cat = machine_model_df.dtypes[machine_model_df.dtypes == \"object\"].index.tolist()\n",
    "\n",
    "# Check the number of unique values in each column\n",
    "machine_model_df[flights_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records:   1165231\n",
      "Total number of columns:   9\n"
     ]
    }
   ],
   "source": [
    "# Evaluate how many records are available in the dataset\n",
    "print('Total number of records:  ', machine_model_df.DAY_OF_MONTH.count())\n",
    "print('Total number of columns:  ', len(machine_model_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 2 - Encoding:\n",
    "#### Encoding Method:\n",
    "A couple of things to note, the complete dataset has over a million records and there are currently 9 columns.  Given the number of columns that have unique string data, to attempt to apply get_dummies would dramatically increase the datatable size.  This was attempted on the Carrier and Origin the result was a error code stating that there was inadequate resources.  \n",
    "\n",
    "We will reserve the get_dummy encoding method for the OP_Carrier and Departure Time Blocks only and will use LabelEncoder for Origin, Destination, and Tail Number.  It is necessary to not limit ourselves to only the top ten of any of these options because these will be unique entries by the user later when the model is being implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform get_dummies method on the OP_Carrier and Departure Time Blocks columns\n",
    "dummy_columns = ['OP_CARRIER', 'DEP_TIME_BLK']\n",
    "prefix = ['Carrier', 'Time_Block']\n",
    "dummy_df = pd.get_dummies(machine_model_df[dummy_columns], prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranform each column with LabelEncoder (https://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn)\n",
    "lableEncoder_columns = ['ORIGIN', 'DEST', 'TAIL_NUM']\n",
    "d = defaultdict(LabelEncoder)\n",
    "\n",
    "df = machine_model_df[lableEncoder_columns]\n",
    "\n",
    "# Encoding the variable\n",
    "labelEncoded_df = df.apply(lambda x: d[x.name].fit_transform(x))\n",
    "\n",
    "# Retaining this code here for later reference\n",
    "## Inverse the encoded\n",
    "# fit.apply(lambda x: d[x.name].inverse_transform(x))\n",
    "\n",
    "## Using the dictionary to label future data\n",
    "# df.apply(lambda x: d[x.name].transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>DEP_DEL15</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>Carrier_9E</th>\n",
       "      <th>Carrier_AA</th>\n",
       "      <th>Carrier_AS</th>\n",
       "      <th>Carrier_B6</th>\n",
       "      <th>Carrier_DL</th>\n",
       "      <th>Carrier_EV</th>\n",
       "      <th>...</th>\n",
       "      <th>Time_Block_1700-1759</th>\n",
       "      <th>Time_Block_1800-1859</th>\n",
       "      <th>Time_Block_1900-1959</th>\n",
       "      <th>Time_Block_2000-2059</th>\n",
       "      <th>Time_Block_2100-2159</th>\n",
       "      <th>Time_Block_2200-2259</th>\n",
       "      <th>Time_Block_2300-2359</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>19</td>\n",
       "      <td>4648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>596</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>82</td>\n",
       "      <td>1542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>229</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>82</td>\n",
       "      <td>4810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>331</td>\n",
       "      <td>19</td>\n",
       "      <td>4806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>579</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>122</td>\n",
       "      <td>4867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DAY_OF_MONTH  DAY_OF_WEEK  DEP_DEL15  DISTANCE  Carrier_9E  Carrier_AA  \\\n",
       "0             1            2          0       300           1           0   \n",
       "1             1            2          0       596           1           0   \n",
       "2             1            2          0       229           1           0   \n",
       "3             1            2          0       223           1           0   \n",
       "4             1            2          0       579           1           0   \n",
       "\n",
       "   Carrier_AS  Carrier_B6  Carrier_DL  Carrier_EV  ...  Time_Block_1700-1759  \\\n",
       "0           0           0           0           0  ...                     0   \n",
       "1           0           0           0           0  ...                     0   \n",
       "2           0           0           0           0  ...                     0   \n",
       "3           0           0           0           0  ...                     0   \n",
       "4           0           0           0           0  ...                     0   \n",
       "\n",
       "   Time_Block_1800-1859  Time_Block_1900-1959  Time_Block_2000-2059  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     1                     0   \n",
       "\n",
       "   Time_Block_2100-2159  Time_Block_2200-2259  Time_Block_2300-2359  ORIGIN  \\\n",
       "0                     0                     0                     0     130   \n",
       "1                     0                     0                     0     227   \n",
       "2                     0                     0                     0      97   \n",
       "3                     0                     0                     0     331   \n",
       "4                     0                     0                     0      19   \n",
       "\n",
       "   DEST  TAIL_NUM  \n",
       "0    19      4648  \n",
       "1    82      1542  \n",
       "2    82      4810  \n",
       "3    19      4806  \n",
       "4   122      4867  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the encoded columns\n",
    "machine_model_df_encoded = machine_model_df.drop(flights_cat, axis=1)\n",
    "machine_model_df_encoded = pd.concat([machine_model_df_encoded, dummy_df, labelEncoded_df], axis = 1)\n",
    "machine_model_df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Feature and Target Variables\n",
    "y = machine_model_df_encoded[\"DEP_DEL15\"]  # Target\n",
    "X = machine_model_df_encoded.drop(columns=\"DEP_DEL15\") # Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Splitting Data:\n",
    "Using the method imported from the package sklearn, the dataset is split into a training set and a test set.\n",
    "The seperation is achived randomly.  \n",
    "By adding the condition stratify = y, we are insuring that the test and training sets contain the proportion \n",
    "of values as provided in the target set.  By setting random_state to a specific value we can get repeatedly the same split of the data so it is possible to make sure that at least the testing and training sets are consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(873923, 42)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=34, \n",
    "                                                    stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess numerical data\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Multiple models were evaluated to determine how well they are able to predict the end result.  It is important to note that there are far fewer delayed flights than flights that are on time.  Because that is true, when evaluating how accurate the model is at predicting we will need to evaluate it using precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Logistic Regression Model\n",
    "classifier = LogisticRegression(solver='lbfgs',\n",
    "                                max_iter=2000,\n",
    "                                random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=2000, random_state=10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prediction  Actual\n",
       "0            0       0\n",
       "1            0       0\n",
       "2            0       0\n",
       "3            0       0\n",
       "4            0       0\n",
       "5            0       0\n",
       "6            0       0\n",
       "7            0       0\n",
       "8            0       0\n",
       "9            0       0\n",
       "10           0       0\n",
       "11           0       0\n",
       "12           0       1\n",
       "13           0       0\n",
       "14           0       0\n",
       "15           0       0\n",
       "16           0       0\n",
       "17           0       1\n",
       "18           0       0\n",
       "19           0       1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions \n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[246370,      0],\n",
       "       [ 44938,      0]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjgla\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92    246370\n",
      "           1       0.00      0.00      0.00     44938\n",
      "\n",
      "    accuracy                           0.85    291308\n",
      "   macro avg       0.42      0.50      0.46    291308\n",
      "weighted avg       0.72      0.85      0.78    291308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Because dataset is imbalanced we cant use accuracy metric\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dt = DecisionTreeClassifier(random_state = 0)\n",
    "model_dt = clf_dt.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86    246370\n",
      "           1       0.27      0.29      0.28     44938\n",
      "\n",
      "    accuracy                           0.77    291308\n",
      "   macro avg       0.57      0.57      0.57    291308\n",
      "weighted avg       0.78      0.77      0.77    291308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_dt.predict(X_test_scaled)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[210549,  35821],\n",
       "       [ 31706,  13232]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prediction  Actual\n",
       "0            1       0\n",
       "1            0       0\n",
       "2            0       0\n",
       "3            1       0\n",
       "4            1       0\n",
       "5            0       0\n",
       "6            0       0\n",
       "7            0       0\n",
       "8            0       0\n",
       "9            0       0\n",
       "10           0       0\n",
       "11           0       0\n",
       "12           0       1\n",
       "13           0       0\n",
       "14           0       0\n",
       "15           0       0\n",
       "16           0       0\n",
       "17           0       1\n",
       "18           0       0\n",
       "19           1       1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier\n",
    "This one is too slow and is demonstrated to be a poor predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier(max_depth=10)\n",
    "model_rf = clf_rf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjgla\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92    246370\n",
      "           1       0.00      0.00      0.00     44938\n",
      "\n",
      "    accuracy                           0.85    291308\n",
      "   macro avg       0.42      0.50      0.46    291308\n",
      "weighted avg       0.72      0.85      0.78    291308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_rf.predict(X_test_scaled)\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[246370,      0],\n",
       "       [ 44938,      0]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "27311/27311 [==============================] - 18s 668us/step - loss: 0.4174 - accuracy: 0.8453\n",
      "Epoch 2/100\n",
      "27311/27311 [==============================] - 18s 662us/step - loss: 0.4140 - accuracy: 0.8457\n",
      "Epoch 3/100\n",
      "27311/27311 [==============================] - 18s 676us/step - loss: 0.4127 - accuracy: 0.8457\n",
      "Epoch 4/100\n",
      "27311/27311 [==============================] - 19s 681us/step - loss: 0.4119 - accuracy: 0.8457\n",
      "Epoch 5/100\n",
      "27311/27311 [==============================] - 18s 652us/step - loss: 0.4110 - accuracy: 0.8457\n",
      "Epoch 6/100\n",
      "27311/27311 [==============================] - 19s 701us/step - loss: 0.4102 - accuracy: 0.8457\n",
      "Epoch 7/100\n",
      "27311/27311 [==============================] - 21s 757us/step - loss: 0.4096 - accuracy: 0.8457\n",
      "Epoch 8/100\n",
      "27311/27311 [==============================] - 18s 671us/step - loss: 0.4091 - accuracy: 0.8457\n",
      "Epoch 9/100\n",
      "27311/27311 [==============================] - 18s 661us/step - loss: 0.4088 - accuracy: 0.8457\n",
      "Epoch 10/100\n",
      "27311/27311 [==============================] - 18s 650us/step - loss: 0.4084 - accuracy: 0.8458\n",
      "Epoch 11/100\n",
      "27311/27311 [==============================] - 17s 638us/step - loss: 0.4082 - accuracy: 0.8458\n",
      "Epoch 12/100\n",
      "27311/27311 [==============================] - 19s 687us/step - loss: 0.4080 - accuracy: 0.8458\n",
      "Epoch 13/100\n",
      "27311/27311 [==============================] - 18s 662us/step - loss: 0.4078 - accuracy: 0.8458\n",
      "Epoch 14/100\n",
      "27311/27311 [==============================] - 18s 655us/step - loss: 0.4076 - accuracy: 0.8458\n",
      "Epoch 15/100\n",
      "27311/27311 [==============================] - 18s 651us/step - loss: 0.4075 - accuracy: 0.8458\n",
      "Epoch 16/100\n",
      "27311/27311 [==============================] - 18s 641us/step - loss: 0.4073 - accuracy: 0.8458\n",
      "Epoch 17/100\n",
      "27311/27311 [==============================] - 18s 658us/step - loss: 0.4071 - accuracy: 0.8458\n",
      "Epoch 18/100\n",
      "27311/27311 [==============================] - 18s 672us/step - loss: 0.4071 - accuracy: 0.8458\n",
      "Epoch 19/100\n",
      "27311/27311 [==============================] - 18s 668us/step - loss: 0.4069 - accuracy: 0.8459\n",
      "Epoch 20/100\n",
      "27311/27311 [==============================] - 19s 706us/step - loss: 0.4067 - accuracy: 0.8458\n",
      "Epoch 21/100\n",
      "27311/27311 [==============================] - 18s 671us/step - loss: 0.4067 - accuracy: 0.8459\n",
      "Epoch 22/100\n",
      "27311/27311 [==============================] - 19s 696us/step - loss: 0.4066 - accuracy: 0.8459\n",
      "Epoch 23/100\n",
      "27311/27311 [==============================] - 18s 666us/step - loss: 0.4064 - accuracy: 0.8459\n",
      "Epoch 24/100\n",
      "27311/27311 [==============================] - 18s 651us/step - loss: 0.4064 - accuracy: 0.8459\n",
      "Epoch 25/100\n",
      "27311/27311 [==============================] - 19s 701us/step - loss: 0.4063 - accuracy: 0.8459\n",
      "Epoch 26/100\n",
      "27311/27311 [==============================] - 18s 649us/step - loss: 0.4063 - accuracy: 0.8459\n",
      "Epoch 27/100\n",
      "27311/27311 [==============================] - 18s 652us/step - loss: 0.4062 - accuracy: 0.8458\n",
      "Epoch 28/100\n",
      "27311/27311 [==============================] - 18s 664us/step - loss: 0.4061 - accuracy: 0.8459\n",
      "Epoch 29/100\n",
      "27311/27311 [==============================] - 18s 660us/step - loss: 0.4061 - accuracy: 0.8459\n",
      "Epoch 30/100\n",
      "27311/27311 [==============================] - 18s 674us/step - loss: 0.4061 - accuracy: 0.8459\n",
      "Epoch 31/100\n",
      "27311/27311 [==============================] - 19s 698us/step - loss: 0.4059 - accuracy: 0.8458\n",
      "Epoch 32/100\n",
      "27311/27311 [==============================] - 19s 685us/step - loss: 0.4059 - accuracy: 0.8459\n",
      "Epoch 33/100\n",
      "27311/27311 [==============================] - 19s 680us/step - loss: 0.4060 - accuracy: 0.8459\n",
      "Epoch 34/100\n",
      "27311/27311 [==============================] - 19s 700us/step - loss: 0.4058 - accuracy: 0.8459\n",
      "Epoch 35/100\n",
      "27311/27311 [==============================] - 19s 698us/step - loss: 0.4058 - accuracy: 0.8459\n",
      "Epoch 36/100\n",
      "27311/27311 [==============================] - 19s 706us/step - loss: 0.4058 - accuracy: 0.8459\n",
      "Epoch 37/100\n",
      "27311/27311 [==============================] - 20s 722us/step - loss: 0.4057 - accuracy: 0.8459\n",
      "Epoch 38/100\n",
      "27311/27311 [==============================] - 18s 667us/step - loss: 0.4056 - accuracy: 0.8459\n",
      "Epoch 39/100\n",
      "27311/27311 [==============================] - 18s 665us/step - loss: 0.4056 - accuracy: 0.8458\n",
      "Epoch 40/100\n",
      "27311/27311 [==============================] - 18s 673us/step - loss: 0.4056 - accuracy: 0.8459\n",
      "Epoch 41/100\n",
      "27311/27311 [==============================] - 18s 661us/step - loss: 0.4055 - accuracy: 0.8460\n",
      "Epoch 42/100\n",
      "27311/27311 [==============================] - 18s 664us/step - loss: 0.4055 - accuracy: 0.8459\n",
      "Epoch 43/100\n",
      "27311/27311 [==============================] - 18s 673us/step - loss: 0.4054 - accuracy: 0.8460\n",
      "Epoch 44/100\n",
      "27311/27311 [==============================] - 19s 680us/step - loss: 0.4053 - accuracy: 0.8459\n",
      "Epoch 45/100\n",
      "27311/27311 [==============================] - 19s 713us/step - loss: 0.4054 - accuracy: 0.8459\n",
      "Epoch 46/100\n",
      "27311/27311 [==============================] - 18s 669us/step - loss: 0.4054 - accuracy: 0.8459\n",
      "Epoch 47/100\n",
      "27311/27311 [==============================] - 19s 682us/step - loss: 0.4053 - accuracy: 0.8459\n",
      "Epoch 48/100\n",
      "27311/27311 [==============================] - 18s 669us/step - loss: 0.4052 - accuracy: 0.8459\n",
      "Epoch 49/100\n",
      "27311/27311 [==============================] - 18s 660us/step - loss: 0.4053 - accuracy: 0.8459\n",
      "Epoch 50/100\n",
      "27311/27311 [==============================] - 19s 699us/step - loss: 0.4052 - accuracy: 0.8459\n",
      "Epoch 51/100\n",
      "27311/27311 [==============================] - 18s 672us/step - loss: 0.4052 - accuracy: 0.8459\n",
      "Epoch 52/100\n",
      "27311/27311 [==============================] - 18s 672us/step - loss: 0.4052 - accuracy: 0.8459\n",
      "Epoch 53/100\n",
      "27311/27311 [==============================] - 18s 658us/step - loss: 0.4051 - accuracy: 0.8460\n",
      "Epoch 54/100\n",
      "27311/27311 [==============================] - 18s 666us/step - loss: 0.4051 - accuracy: 0.8460\n",
      "Epoch 55/100\n",
      "27311/27311 [==============================] - 19s 690us/step - loss: 0.4051 - accuracy: 0.8460\n",
      "Epoch 56/100\n",
      "27311/27311 [==============================] - 19s 689us/step - loss: 0.4052 - accuracy: 0.8460\n",
      "Epoch 57/100\n",
      "27311/27311 [==============================] - 19s 694us/step - loss: 0.4050 - accuracy: 0.8460\n",
      "Epoch 58/100\n",
      "27311/27311 [==============================] - 19s 700us/step - loss: 0.4051 - accuracy: 0.8459\n",
      "Epoch 59/100\n",
      "27311/27311 [==============================] - 19s 678us/step - loss: 0.4050 - accuracy: 0.8459\n",
      "Epoch 60/100\n",
      "27311/27311 [==============================] - 18s 677us/step - loss: 0.4050 - accuracy: 0.8460\n",
      "Epoch 61/100\n",
      "27311/27311 [==============================] - 19s 683us/step - loss: 0.4050 - accuracy: 0.8459\n",
      "Epoch 62/100\n",
      "27311/27311 [==============================] - 18s 675us/step - loss: 0.4049 - accuracy: 0.8459\n",
      "Epoch 63/100\n",
      "27311/27311 [==============================] - 19s 709us/step - loss: 0.4049 - accuracy: 0.8460\n",
      "Epoch 64/100\n",
      "27311/27311 [==============================] - 20s 727us/step - loss: 0.4049 - accuracy: 0.8461\n",
      "Epoch 65/100\n",
      "27311/27311 [==============================] - 18s 677us/step - loss: 0.4049 - accuracy: 0.8460\n",
      "Epoch 66/100\n",
      "27311/27311 [==============================] - 18s 670us/step - loss: 0.4050 - accuracy: 0.8460\n",
      "Epoch 67/100\n",
      "27311/27311 [==============================] - 18s 676us/step - loss: 0.4048 - accuracy: 0.8460\n",
      "Epoch 68/100\n",
      "27311/27311 [==============================] - 18s 671us/step - loss: 0.4048 - accuracy: 0.8460\n",
      "Epoch 69/100\n",
      "27311/27311 [==============================] - 19s 678us/step - loss: 0.4048 - accuracy: 0.8460\n",
      "Epoch 70/100\n",
      "27311/27311 [==============================] - 19s 678us/step - loss: 0.4048 - accuracy: 0.8460\n",
      "Epoch 71/100\n",
      "27311/27311 [==============================] - 19s 681us/step - loss: 0.4048 - accuracy: 0.8460\n",
      "Epoch 72/100\n",
      "27311/27311 [==============================] - 19s 682us/step - loss: 0.4048 - accuracy: 0.8461\n",
      "Epoch 73/100\n",
      "27311/27311 [==============================] - 19s 680us/step - loss: 0.4048 - accuracy: 0.8461\n",
      "Epoch 74/100\n",
      "27311/27311 [==============================] - 19s 704us/step - loss: 0.4048 - accuracy: 0.8461\n",
      "Epoch 75/100\n",
      "27311/27311 [==============================] - 19s 703us/step - loss: 0.4048 - accuracy: 0.8460\n",
      "Epoch 76/100\n",
      "27311/27311 [==============================] - 18s 677us/step - loss: 0.4048 - accuracy: 0.8460\n",
      "Epoch 77/100\n",
      "27311/27311 [==============================] - 18s 645us/step - loss: 0.4047 - accuracy: 0.8460\n",
      "Epoch 78/100\n",
      "27311/27311 [==============================] - 16s 599us/step - loss: 0.4047 - accuracy: 0.8461\n",
      "Epoch 79/100\n",
      "27311/27311 [==============================] - 16s 600us/step - loss: 0.4047 - accuracy: 0.8460\n",
      "Epoch 80/100\n",
      "27311/27311 [==============================] - 16s 604us/step - loss: 0.4047 - accuracy: 0.8460\n",
      "Epoch 81/100\n",
      "27311/27311 [==============================] - 16s 600us/step - loss: 0.4046 - accuracy: 0.8461\n",
      "Epoch 82/100\n",
      "27311/27311 [==============================] - 17s 604us/step - loss: 0.4046 - accuracy: 0.8461\n",
      "Epoch 83/100\n",
      "27311/27311 [==============================] - 17s 620us/step - loss: 0.4046 - accuracy: 0.8461\n",
      "Epoch 84/100\n",
      "27311/27311 [==============================] - 16s 600us/step - loss: 0.4046 - accuracy: 0.8461\n",
      "Epoch 85/100\n",
      "27311/27311 [==============================] - 16s 597us/step - loss: 0.4046 - accuracy: 0.8461\n",
      "Epoch 86/100\n",
      "27311/27311 [==============================] - 17s 616us/step - loss: 0.4046 - accuracy: 0.8461\n",
      "Epoch 87/100\n",
      "27311/27311 [==============================] - 17s 627us/step - loss: 0.4046 - accuracy: 0.8461\n",
      "Epoch 88/100\n",
      "27311/27311 [==============================] - 16s 600us/step - loss: 0.4045 - accuracy: 0.8461\n",
      "Epoch 89/100\n",
      "27311/27311 [==============================] - 16s 595us/step - loss: 0.4045 - accuracy: 0.8461\n",
      "Epoch 90/100\n",
      "27311/27311 [==============================] - 16s 604us/step - loss: 0.4045 - accuracy: 0.8461\n",
      "Epoch 91/100\n",
      "27311/27311 [==============================] - 16s 602us/step - loss: 0.4045 - accuracy: 0.8461\n",
      "Epoch 92/100\n",
      "27311/27311 [==============================] - 16s 601us/step - loss: 0.4045 - accuracy: 0.8461\n",
      "Epoch 93/100\n",
      "27311/27311 [==============================] - 16s 599us/step - loss: 0.4044 - accuracy: 0.8461\n",
      "Epoch 94/100\n",
      "27311/27311 [==============================] - 16s 600us/step - loss: 0.4044 - accuracy: 0.8461\n",
      "Epoch 95/100\n",
      "27311/27311 [==============================] - 16s 600us/step - loss: 0.4042 - accuracy: 0.8461\n",
      "Epoch 96/100\n",
      "27311/27311 [==============================] - 16s 598us/step - loss: 0.4041 - accuracy: 0.8461\n",
      "Epoch 97/100\n",
      "27311/27311 [==============================] - 16s 600us/step - loss: 0.4041 - accuracy: 0.8460\n",
      "Epoch 98/100\n",
      "27311/27311 [==============================] - 17s 604us/step - loss: 0.4041 - accuracy: 0.8461\n",
      "Epoch 99/100\n",
      "27311/27311 [==============================] - 16s 601us/step - loss: 0.4040 - accuracy: 0.8461\n",
      "Epoch 100/100\n",
      "27311/27311 [==============================] - 16s 601us/step - loss: 0.4039 - accuracy: 0.8462\n",
      "9104/9104 - 4s - loss: 0.4080 - accuracy: 0.8458\n",
      "Loss: 0.4080069363117218, Accuracy: 0.8458263874053955\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 =  1.5 * len(X_train_scaled[0])\n",
    "hidden_nodes_layer2 = 12\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Predictions\n",
    "y_pred = tf.round(nn.predict(X_test_scaled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92    246370\n",
      "           1       0.52      0.01      0.01     44938\n",
      "\n",
      "    accuracy                           0.85    291308\n",
      "   macro avg       0.68      0.50      0.47    291308\n",
      "weighted avg       0.80      0.85      0.78    291308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[246083,    287],\n",
       "       [ 44625,    313]], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Final Selection\n",
    "After evaluating each model using the entire combined dataset, it was found that Decision Tree was the best at predicting delays.  That will be the model we will use going forward."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
