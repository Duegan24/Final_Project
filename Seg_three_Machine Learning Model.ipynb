{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "from path import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from collections import defaultdict\n",
    "import pickle, os\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary data preprocessing\n",
    "Original Dataset was provided by a Kaggle Project.  For the intial analysis of the dataset the information was imported to a local directory and then imported read into this jupyter notebook.  Later we will have the connection to the database here. The dataset already came as a csv file so no further processing was necessary.  \n",
    "\n",
    "Merging of the weather data was accomplished by using the World Weather Online API.  The download of the required information was achieved in a seperate jupyter notebook.  Data was formated as a simple csv file and was imported below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Flights for 2019:  565963   Total Flights for 2020:  599268\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>OP_CARRIER_AIRLINE_ID</th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN_AIRPORT_ID</th>\n",
       "      <th>ORIGIN_AIRPORT_SEQ_ID</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST_AIRPORT_ID</th>\n",
       "      <th>DEST_AIRPORT_SEQ_ID</th>\n",
       "      <th>DEST</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DEL15</th>\n",
       "      <th>DEP_TIME_BLK</th>\n",
       "      <th>ARR_TIME</th>\n",
       "      <th>ARR_DEL15</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>DISTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20363</td>\n",
       "      <td>9E</td>\n",
       "      <td>N8688C</td>\n",
       "      <td>3280</td>\n",
       "      <td>11953</td>\n",
       "      <td>1195302</td>\n",
       "      <td>GNV</td>\n",
       "      <td>10397</td>\n",
       "      <td>1039707</td>\n",
       "      <td>ATL</td>\n",
       "      <td>601.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0600-0659</td>\n",
       "      <td>722.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20363</td>\n",
       "      <td>9E</td>\n",
       "      <td>N348PQ</td>\n",
       "      <td>3281</td>\n",
       "      <td>13487</td>\n",
       "      <td>1348702</td>\n",
       "      <td>MSP</td>\n",
       "      <td>11193</td>\n",
       "      <td>1119302</td>\n",
       "      <td>CVG</td>\n",
       "      <td>1359.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1400-1459</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20363</td>\n",
       "      <td>9E</td>\n",
       "      <td>N8896A</td>\n",
       "      <td>3282</td>\n",
       "      <td>11433</td>\n",
       "      <td>1143302</td>\n",
       "      <td>DTW</td>\n",
       "      <td>11193</td>\n",
       "      <td>1119302</td>\n",
       "      <td>CVG</td>\n",
       "      <td>1215.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1200-1259</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20363</td>\n",
       "      <td>9E</td>\n",
       "      <td>N8886A</td>\n",
       "      <td>3283</td>\n",
       "      <td>15249</td>\n",
       "      <td>1524906</td>\n",
       "      <td>TLH</td>\n",
       "      <td>10397</td>\n",
       "      <td>1039707</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1521.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500-1559</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20363</td>\n",
       "      <td>9E</td>\n",
       "      <td>N8974C</td>\n",
       "      <td>3284</td>\n",
       "      <td>10397</td>\n",
       "      <td>1039707</td>\n",
       "      <td>ATL</td>\n",
       "      <td>11778</td>\n",
       "      <td>1177801</td>\n",
       "      <td>FSM</td>\n",
       "      <td>1847.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1900-1959</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DAY_OF_MONTH  DAY_OF_WEEK  OP_CARRIER_AIRLINE_ID OP_CARRIER TAIL_NUM  \\\n",
       "0             1            2                  20363         9E   N8688C   \n",
       "1             1            2                  20363         9E   N348PQ   \n",
       "2             1            2                  20363         9E   N8896A   \n",
       "3             1            2                  20363         9E   N8886A   \n",
       "4             1            2                  20363         9E   N8974C   \n",
       "\n",
       "   OP_CARRIER_FL_NUM  ORIGIN_AIRPORT_ID  ORIGIN_AIRPORT_SEQ_ID ORIGIN  \\\n",
       "0               3280              11953                1195302    GNV   \n",
       "1               3281              13487                1348702    MSP   \n",
       "2               3282              11433                1143302    DTW   \n",
       "3               3283              15249                1524906    TLH   \n",
       "4               3284              10397                1039707    ATL   \n",
       "\n",
       "   DEST_AIRPORT_ID  DEST_AIRPORT_SEQ_ID DEST  DEP_TIME  DEP_DEL15  \\\n",
       "0            10397              1039707  ATL     601.0        0.0   \n",
       "1            11193              1119302  CVG    1359.0        0.0   \n",
       "2            11193              1119302  CVG    1215.0        0.0   \n",
       "3            10397              1039707  ATL    1521.0        0.0   \n",
       "4            11778              1177801  FSM    1847.0        0.0   \n",
       "\n",
       "  DEP_TIME_BLK  ARR_TIME  ARR_DEL15  CANCELLED  DIVERTED  DISTANCE  \n",
       "0    0600-0659     722.0        0.0          0         0       300  \n",
       "1    1400-1459    1633.0        0.0          0         0       596  \n",
       "2    1200-1259    1329.0        0.0          0         0       229  \n",
       "3    1500-1559    1625.0        0.0          0         0       223  \n",
       "4    1900-1959    1940.0        0.0          0         0       579  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import testing dataset\n",
    "flights_2019 = pd.read_csv('Database/Data/jan_19_clean.csv')\n",
    "flights_2020 = pd.read_csv('Database/Data/jan_20_clean.csv')\n",
    "\n",
    "print('Total Flights for 2019: ', len(flights_2019)\n",
    "      , '  Total Flights for 2020: ', len(flights_2020))\n",
    "\n",
    "flights_2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2019['Year'] = 2019\n",
    "flights_2020['Year'] = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flights_2020.ORIGIN.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>date_time</th>\n",
       "      <th>precipMM</th>\n",
       "      <th>visibility</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>windspeedKmph</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>islip,ny</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>8.5</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>islip,ny</td>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>12</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>islip,ny</td>\n",
       "      <td>2019-01-01 02:00:00</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>islip,ny</td>\n",
       "      <td>2019-01-01 03:00:00</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>18</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>islip,ny</td>\n",
       "      <td>2019-01-01 04:00:00</td>\n",
       "      <td>2.9</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>20</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   location            date_time  precipMM  visibility  cloudcover  \\\n",
       "0  islip,ny  2019-01-01 00:00:00       8.5           5         100   \n",
       "1  islip,ny  2019-01-01 01:00:00       4.3           5         100   \n",
       "2  islip,ny  2019-01-01 02:00:00       4.3           6         100   \n",
       "3  islip,ny  2019-01-01 03:00:00       5.8           6         100   \n",
       "4  islip,ny  2019-01-01 04:00:00       2.9           7          98   \n",
       "\n",
       "   windspeedKmph  humidity  \n",
       "0             10        91  \n",
       "1             12        93  \n",
       "2             15        94  \n",
       "3             18        96  \n",
       "4             20        96  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Weather Data\n",
    "weather_2018 = pd.read_csv('Database/weather/weather_data/weather_2019_df.csv')\n",
    "weather_2019 = pd.read_csv('Database/weather/weather_data/weather_2019_df.csv')\n",
    "weather_2020 = pd.read_csv('Database/weather/weather_data/weather_2020_df.csv')\n",
    "\n",
    "# Combine the weather dataframes\n",
    "weather_df = pd.concat([weather_2018, weather_2019, weather_2020])\n",
    "\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weather_df.location.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "709776"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airport Code</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABR</td>\n",
       "      <td>aberdeen,sd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABI</td>\n",
       "      <td>abilene,tx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADK</td>\n",
       "      <td>adakisland,ak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAK</td>\n",
       "      <td>akron,oh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALB</td>\n",
       "      <td>albany,ny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Airport Code       location\n",
       "0          ABR    aberdeen,sd\n",
       "1          ABI     abilene,tx\n",
       "2          ADK  adakisland,ak\n",
       "3          CAK       akron,oh\n",
       "4          ALB      albany,ny"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import airport city information\n",
    "locations_lookup_df = pd.read_csv(\"Flight_data_files/post_hardcode_cities.csv\")\n",
    "locations_lookup_df.drop(columns = \"Unnamed: 0\", axis = 1, inplace = True)\n",
    "locations_lookup_df.rename(columns = {\"City\": \"location\"}, inplace = True )\n",
    "locations_lookup_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_merged = pd.merge(weather_df, locations_lookup_df, on = \"location\", how = \"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_merged[weather_merged['Airport Code'].isnull()].location.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_merged.date_time = weather_merged.date_time.astype('datetime64[ns]')\n",
    "weather_merged['Year'] = weather_merged.date_time.dt.year\n",
    "weather_merged['Month'] = weather_merged.date_time.dt.month\n",
    "weather_merged['Day'] = weather_merged.date_time.dt.day\n",
    "weather_merged['Hour'] = weather_merged.date_time.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>date_time</th>\n",
       "      <th>precipMM</th>\n",
       "      <th>visibility</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>windspeedKmph</th>\n",
       "      <th>humidity</th>\n",
       "      <th>Airport Code</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>islip,ny</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>8.5</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>91</td>\n",
       "      <td>ISP</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>islip,ny</td>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>12</td>\n",
       "      <td>93</td>\n",
       "      <td>ISP</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>islip,ny</td>\n",
       "      <td>2019-01-01 02:00:00</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "      <td>94</td>\n",
       "      <td>ISP</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>islip,ny</td>\n",
       "      <td>2019-01-01 03:00:00</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>18</td>\n",
       "      <td>96</td>\n",
       "      <td>ISP</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>islip,ny</td>\n",
       "      <td>2019-01-01 04:00:00</td>\n",
       "      <td>2.9</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>20</td>\n",
       "      <td>96</td>\n",
       "      <td>ISP</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   location           date_time  precipMM  visibility  cloudcover  \\\n",
       "0  islip,ny 2019-01-01 00:00:00       8.5           5         100   \n",
       "1  islip,ny 2019-01-01 01:00:00       4.3           5         100   \n",
       "2  islip,ny 2019-01-01 02:00:00       4.3           6         100   \n",
       "3  islip,ny 2019-01-01 03:00:00       5.8           6         100   \n",
       "4  islip,ny 2019-01-01 04:00:00       2.9           7          98   \n",
       "\n",
       "   windspeedKmph  humidity Airport Code  Year  Month  Day  Hour  \n",
       "0             10        91          ISP  2019      1    1     0  \n",
       "1             12        93          ISP  2019      1    1     1  \n",
       "2             15        94          ISP  2019      1    1     2  \n",
       "3             18        96          ISP  2019      1    1     3  \n",
       "4             20        96          ISP  2019      1    1     4  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Feature Engineering\n",
    "Beyond a visual inspection of the head of the data the following steps were performed below:\n",
    "\n",
    "1) Determined if there are any rows that need to be dropped because they are missing data.\n",
    "\n",
    "2) Determine which columns of data will need to be included in the training set.\n",
    "\n",
    "3) Perform the inital encoding of the columns that contained objects as numerical values so it would be easier for the machine learning model to process it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows with missing information from 2019 data was:   0\n"
     ]
    }
   ],
   "source": [
    "na_count = flights_2019.DAY_OF_MONTH.count() - flights_2019.dropna(axis=0).DAY_OF_MONTH.count()\n",
    "print('Total rows with missing information from 2019 data was:  ', na_count )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows with missing information from 2019 data was:   0\n"
     ]
    }
   ],
   "source": [
    "na_count = flights_2020.DAY_OF_MONTH.count() - flights_2020.dropna(axis=0).DAY_OF_MONTH.count()\n",
    "print('Total rows with missing information from 2019 data was:  ', na_count )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step one complete.  The datasets are already cleaned with no missing information in any of the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two data sets to give more data for the model to work with\n",
    "flights = pd.concat([flights_2019, flights_2020])\n",
    "flights['Month'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preporation to Merge in Weather Data, add hour column\n",
    "flights['DEP_Hour'] = (flights['DEP_TIME']/100).astype(\"int\")\n",
    "flights['DEP_Hour'] = flights['DEP_Hour'].replace(24, 0) # replace 24 hours with 0 to match weather data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DAY_OF_MONTH', 'DAY_OF_WEEK', 'OP_CARRIER_AIRLINE_ID', 'OP_CARRIER',\n",
       "       'TAIL_NUM', 'OP_CARRIER_FL_NUM', 'ORIGIN_AIRPORT_ID',\n",
       "       'ORIGIN_AIRPORT_SEQ_ID', 'ORIGIN', 'DEST_AIRPORT_ID',\n",
       "       'DEST_AIRPORT_SEQ_ID', 'DEST', 'DEP_TIME', 'DEP_DEL15', 'DEP_TIME_BLK',\n",
       "       'ARR_TIME', 'ARR_DEL15', 'CANCELLED', 'DIVERTED', 'DISTANCE', 'Year',\n",
       "       'Month', 'DEP_Hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Look at the available columns\n",
    "flights.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1165231"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_merged = pd.merge(flights, weather_merged\n",
    "                          ,  how='left'\n",
    "                          , left_on=['ORIGIN', 'Year', 'Month', 'DAY_OF_MONTH' , 'DEP_Hour']\n",
    "                          , right_on = ['Airport Code', 'Year', 'Month', 'Day', 'Hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1720680"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flights_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredList = ['DAY_OF_MONTH', 'DAY_OF_WEEK', 'OP_CARRIER', 'ORIGIN', 'DEST', 'DEP_DEL15', 'DISTANCE'\n",
    "                ,'DEP_TIME_BLK', 'TAIL_NUM']\n",
    "\n",
    "flights_merged = flights_merged.drop_duplicates(subset = filteredList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1165231"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flights_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>OP_CARRIER_AIRLINE_ID</th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN_AIRPORT_ID</th>\n",
       "      <th>ORIGIN_AIRPORT_SEQ_ID</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST_AIRPORT_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>location</th>\n",
       "      <th>date_time</th>\n",
       "      <th>precipMM</th>\n",
       "      <th>visibility</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>windspeedKmph</th>\n",
       "      <th>humidity</th>\n",
       "      <th>Airport Code</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20363</td>\n",
       "      <td>9E</td>\n",
       "      <td>N8688C</td>\n",
       "      <td>3280</td>\n",
       "      <td>11953</td>\n",
       "      <td>1195302</td>\n",
       "      <td>GNV</td>\n",
       "      <td>10397</td>\n",
       "      <td>...</td>\n",
       "      <td>gainesville,fl</td>\n",
       "      <td>2019-01-01 06:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>GNV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20363</td>\n",
       "      <td>9E</td>\n",
       "      <td>N348PQ</td>\n",
       "      <td>3281</td>\n",
       "      <td>13487</td>\n",
       "      <td>1348702</td>\n",
       "      <td>MSP</td>\n",
       "      <td>11193</td>\n",
       "      <td>...</td>\n",
       "      <td>minneapolis,mn</td>\n",
       "      <td>2019-01-01 13:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>MSP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20363</td>\n",
       "      <td>9E</td>\n",
       "      <td>N8896A</td>\n",
       "      <td>3282</td>\n",
       "      <td>11433</td>\n",
       "      <td>1143302</td>\n",
       "      <td>DTW</td>\n",
       "      <td>11193</td>\n",
       "      <td>...</td>\n",
       "      <td>detroit,mi</td>\n",
       "      <td>2019-01-01 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>DTW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20363</td>\n",
       "      <td>9E</td>\n",
       "      <td>N8886A</td>\n",
       "      <td>3283</td>\n",
       "      <td>15249</td>\n",
       "      <td>1524906</td>\n",
       "      <td>TLH</td>\n",
       "      <td>10397</td>\n",
       "      <td>...</td>\n",
       "      <td>tallahassee,fl</td>\n",
       "      <td>2019-01-01 15:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>TLH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20363</td>\n",
       "      <td>9E</td>\n",
       "      <td>N8974C</td>\n",
       "      <td>3284</td>\n",
       "      <td>10397</td>\n",
       "      <td>1039707</td>\n",
       "      <td>ATL</td>\n",
       "      <td>11778</td>\n",
       "      <td>...</td>\n",
       "      <td>atlanta,ga</td>\n",
       "      <td>2019-01-01 18:00:00</td>\n",
       "      <td>2.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DAY_OF_MONTH  DAY_OF_WEEK  OP_CARRIER_AIRLINE_ID OP_CARRIER TAIL_NUM  \\\n",
       "0             1            2                  20363         9E   N8688C   \n",
       "2             1            2                  20363         9E   N348PQ   \n",
       "4             1            2                  20363         9E   N8896A   \n",
       "6             1            2                  20363         9E   N8886A   \n",
       "8             1            2                  20363         9E   N8974C   \n",
       "\n",
       "   OP_CARRIER_FL_NUM  ORIGIN_AIRPORT_ID  ORIGIN_AIRPORT_SEQ_ID ORIGIN  \\\n",
       "0               3280              11953                1195302    GNV   \n",
       "2               3281              13487                1348702    MSP   \n",
       "4               3282              11433                1143302    DTW   \n",
       "6               3283              15249                1524906    TLH   \n",
       "8               3284              10397                1039707    ATL   \n",
       "\n",
       "   DEST_AIRPORT_ID  ...        location           date_time  precipMM  \\\n",
       "0            10397  ...  gainesville,fl 2019-01-01 06:00:00       0.0   \n",
       "2            11193  ...  minneapolis,mn 2019-01-01 13:00:00       0.0   \n",
       "4            11193  ...      detroit,mi 2019-01-01 12:00:00       0.0   \n",
       "6            10397  ...  tallahassee,fl 2019-01-01 15:00:00       0.0   \n",
       "8            11778  ...      atlanta,ga 2019-01-01 18:00:00       2.4   \n",
       "\n",
       "   visibility cloudcover  windspeedKmph  humidity  Airport Code  Day  Hour  \n",
       "0        10.0       31.0            4.0      97.0           GNV  1.0   6.0  \n",
       "2        10.0       56.0           10.0      68.0           MSP  1.0  13.0  \n",
       "4         7.0      100.0           21.0      77.0           DTW  1.0  12.0  \n",
       "6        10.0       52.0           10.0      80.0           TLH  1.0  15.0  \n",
       "8         7.0       88.0           10.0      74.0           ATL  1.0  18.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_Airports = flights_merged[flights_merged['Airport Code'].isnull()].ORIGIN.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EWN', 'DRT', 'GRK', 'SWO', 'AZA', 'PGD', 'SFB', 'PBG', 'USA',\n",
       "       'IAG', 'STX', 'BQN', 'STT', 'HOB', 'ECP', 'ACY', 'DAL', 'FCA',\n",
       "       'ABY', 'MMH', 'LCK', 'GUM', 'SPN', 'PVU', 'RFD', 'PPG', 'OGD',\n",
       "       'LYH', 'XWA', 'PAE', 'BFM'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_Airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21645"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing airports that do not have weather data\n",
    "flights_cleaned_merged = flights_merged.dropna()\n",
    "len(flights_merged) - len(flights_cleaned_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DAY_OF_MONTH', 'DAY_OF_WEEK', 'OP_CARRIER_AIRLINE_ID', 'OP_CARRIER',\n",
       "       'TAIL_NUM', 'OP_CARRIER_FL_NUM', 'ORIGIN_AIRPORT_ID',\n",
       "       'ORIGIN_AIRPORT_SEQ_ID', 'ORIGIN', 'DEST_AIRPORT_ID',\n",
       "       'DEST_AIRPORT_SEQ_ID', 'DEST', 'DEP_TIME', 'DEP_DEL15', 'DEP_TIME_BLK',\n",
       "       'ARR_TIME', 'ARR_DEL15', 'CANCELLED', 'DIVERTED', 'DISTANCE', 'Year',\n",
       "       'Month', 'DEP_Hour', 'location', 'date_time', 'precipMM', 'visibility',\n",
       "       'cloudcover', 'windspeedKmph', 'humidity', 'Airport Code', 'Day',\n",
       "       'Hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_cleaned_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top 50 most frequent ORIGINS\n",
    "n = 50\n",
    "top_50_ORIGIN = flights_cleaned_merged.ORIGIN.value_counts()[:n].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the top 50 for use for the dashboard\n",
    "top_50 = pd.DataFrame((flights_cleaned_merged.groupby('ORIGIN').ORIGIN.count().sort_values(ascending=False)[:50]))\n",
    "top_50.index.name = \"Airport\"\n",
    "top_50.columns = ['flight_count']\n",
    "top_50.to_csv(\"top_50_ORIGIN_Airports.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flight_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Airport</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ATL</th>\n",
       "      <td>62807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORD</th>\n",
       "      <td>48102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DFW</th>\n",
       "      <td>46523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLT</th>\n",
       "      <td>38641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEN</th>\n",
       "      <td>38373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAX</th>\n",
       "      <td>35307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PHX</th>\n",
       "      <td>29731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IAH</th>\n",
       "      <td>29140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAS</th>\n",
       "      <td>27132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGA</th>\n",
       "      <td>27066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SFO</th>\n",
       "      <td>26576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTW</th>\n",
       "      <td>24838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCO</th>\n",
       "      <td>24558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSP</th>\n",
       "      <td>24155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOS</th>\n",
       "      <td>22807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCA</th>\n",
       "      <td>22632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEA</th>\n",
       "      <td>21586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EWR</th>\n",
       "      <td>21557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JFK</th>\n",
       "      <td>20508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLC</th>\n",
       "      <td>19384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLL</th>\n",
       "      <td>17940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PHL</th>\n",
       "      <td>17637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIA</th>\n",
       "      <td>16125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BWI</th>\n",
       "      <td>15275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAN</th>\n",
       "      <td>14766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPA</th>\n",
       "      <td>13233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BNA</th>\n",
       "      <td>12564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDW</th>\n",
       "      <td>11449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STL</th>\n",
       "      <td>10576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUS</th>\n",
       "      <td>10191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IAD</th>\n",
       "      <td>10143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SJC</th>\n",
       "      <td>9854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOU</th>\n",
       "      <td>9757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RDU</th>\n",
       "      <td>9683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PDX</th>\n",
       "      <td>9556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSY</th>\n",
       "      <td>9192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HNL</th>\n",
       "      <td>8502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCI</th>\n",
       "      <td>8412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMF</th>\n",
       "      <td>8237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OAK</th>\n",
       "      <td>8172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIT</th>\n",
       "      <td>7976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSW</th>\n",
       "      <td>7695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IND</th>\n",
       "      <td>7583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CVG</th>\n",
       "      <td>7258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMH</th>\n",
       "      <td>7252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLE</th>\n",
       "      <td>7240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNA</th>\n",
       "      <td>6636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAT</th>\n",
       "      <td>6415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PBI</th>\n",
       "      <td>5140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUR</th>\n",
       "      <td>4995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         flight_count\n",
       "Airport              \n",
       "ATL             62807\n",
       "ORD             48102\n",
       "DFW             46523\n",
       "CLT             38641\n",
       "DEN             38373\n",
       "LAX             35307\n",
       "PHX             29731\n",
       "IAH             29140\n",
       "LAS             27132\n",
       "LGA             27066\n",
       "SFO             26576\n",
       "DTW             24838\n",
       "MCO             24558\n",
       "MSP             24155\n",
       "BOS             22807\n",
       "DCA             22632\n",
       "SEA             21586\n",
       "EWR             21557\n",
       "JFK             20508\n",
       "SLC             19384\n",
       "FLL             17940\n",
       "PHL             17637\n",
       "MIA             16125\n",
       "BWI             15275\n",
       "SAN             14766\n",
       "TPA             13233\n",
       "BNA             12564\n",
       "MDW             11449\n",
       "STL             10576\n",
       "AUS             10191\n",
       "IAD             10143\n",
       "SJC              9854\n",
       "HOU              9757\n",
       "RDU              9683\n",
       "PDX              9556\n",
       "MSY              9192\n",
       "HNL              8502\n",
       "MCI              8412\n",
       "SMF              8237\n",
       "OAK              8172\n",
       "PIT              7976\n",
       "RSW              7695\n",
       "IND              7583\n",
       "CVG              7258\n",
       "CMH              7252\n",
       "CLE              7240\n",
       "SNA              6636\n",
       "SAT              6415\n",
       "PBI              5140\n",
       "BUR              4995"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_cleaned_filtered = flights_cleaned_merged[flights_cleaned_merged.ORIGIN.isin(top_50_ORIGIN)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "910877"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flights_cleaned_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:\n",
    "#### Feature Selection:\n",
    "\n",
    "To determine which features to include it was important to determine how we want to use the predictive model.\n",
    "In this case we will be taking a set of inputs from the user and displaying which time slot is most likely to not\n",
    "have a flight delay. So we will only include information the model that we can get from the user or provide look up tables for.\n",
    "\n",
    "The filterdList below included all the data that we either we will be able to get from the user, will be a look up\n",
    "or is the primary feature we want to predict. \n",
    "\n",
    "In this case it is whether there will be a departure delay or not the column name DEP_DEL15 will the be feature we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list that we are going to keep as features\n",
    "filteredList = ['OP_CARRIER', 'ORIGIN', 'DEST', 'DEP_DEL15'\n",
    "                ,'DEP_Hour', 'windspeedKmph', 'precipMM']\n",
    "\n",
    "# Keep the list of columns that were removed...possibly for later use.\n",
    "columnsRemoved = ['DAY_OF_WEEK', 'DAY_OF_MONTH', 'visibility', 'OP_CARRIER_AIRLINE_ID', 'DEST_AIRPORT_SEQ_ID', 'ORIGIN_AIRPORT_SEQ_ID' , 'ORIGIN_AIRPORT_ID', 'DISTANCE', 'TAIL_NUM'\n",
    "                  , 'OP_CARRIER_FL_NUM', 'DEST_AIRPORT_ID', 'ARR_TIME', 'ARR_DEL15', 'CANCELLED', 'DIVERTED', 'DEP_TIME', 'DEP_TIME_BLK']\n",
    "\n",
    "# Filter the data to only include the columns we want\n",
    "machine_model_df = flights_cleaned_filtered.filter(filteredList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the feature we want to predict as a integer since on import it was made a float\n",
    "machine_model_df.DEP_DEL15 = machine_model_df.DEP_DEL15.astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>DEP_DEL15</th>\n",
       "      <th>DEP_Hour</th>\n",
       "      <th>windspeedKmph</th>\n",
       "      <th>precipMM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9E</td>\n",
       "      <td>MSP</td>\n",
       "      <td>CVG</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>9E</td>\n",
       "      <td>DTW</td>\n",
       "      <td>CVG</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>9E</td>\n",
       "      <td>ATL</td>\n",
       "      <td>FSM</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>9E</td>\n",
       "      <td>LGA</td>\n",
       "      <td>CVG</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>9E</td>\n",
       "      <td>ATL</td>\n",
       "      <td>BMI</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DAY_OF_WEEK OP_CARRIER ORIGIN DEST  DEP_DEL15  DEP_Hour  windspeedKmph  \\\n",
       "2             2         9E    MSP  CVG          0        13           10.0   \n",
       "4             2         9E    DTW  CVG          0        12           21.0   \n",
       "8             2         9E    ATL  FSM          0        18           10.0   \n",
       "14            2         9E    LGA  CVG          0        15           19.0   \n",
       "18            2         9E    ATL  BMI          0        12           12.0   \n",
       "\n",
       "    precipMM  \n",
       "2        0.0  \n",
       "4        0.0  \n",
       "8        2.4  \n",
       "14       0.1  \n",
       "18       0.1  "
      ]
     },
     "execution_count": 748,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine_model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAY_OF_WEEK        int64\n",
       "OP_CARRIER        object\n",
       "ORIGIN            object\n",
       "DEST              object\n",
       "DEP_DEL15          int32\n",
       "DEP_Hour           int32\n",
       "windspeedKmph    float64\n",
       "precipMM         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine_model_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are evaluating the impact of including Departure Time and a floating number in the dataset.\n",
    "# if it is there then make it an integer\n",
    "if \"DEP_TIME\" in machine_model_df.columns:\n",
    "    machine_model_df.DEP_TIME = machine_model_df.DEP_TIME.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAY_OF_WEEK        int64\n",
       "OP_CARRIER        object\n",
       "ORIGIN            object\n",
       "DEST              object\n",
       "DEP_DEL15          int32\n",
       "DEP_Hour           int32\n",
       "windspeedKmph    float64\n",
       "precipMM         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine features and determine how the various features will need to be encoded\n",
    "machine_model_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OP_CARRIER     17\n",
       "ORIGIN         50\n",
       "DEST          334\n",
       "dtype: int64"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate our categorical variable list\n",
    "flights_cat = machine_model_df.dtypes[machine_model_df.dtypes == \"object\"].index.tolist()\n",
    "\n",
    "# Check the number of unique values in each column\n",
    "machine_model_df[flights_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records:   910877\n",
      "Total number of columns:   8\n"
     ]
    }
   ],
   "source": [
    "# Evaluate how many records are available in the dataset\n",
    "print('Total number of records:  ', machine_model_df.ORIGIN.count())\n",
    "print('Total number of columns:  ', len(machine_model_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 2 - Encoding:\n",
    "#### Encoding Method:\n",
    "A couple of things to note, the complete dataset has over a million records and there are currently 9 columns.  Given the number of columns that have unique string data, to attempt to apply get_dummies would dramatically increase the datatable size.  This was attempted on the Carrier and Origin the result was a error code stating that there was inadequate resources.  \n",
    "\n",
    "We will reserve the get_dummy encoding method for the OP_Carrier and Departure Time Blocks only and will use LabelEncoder for Origin, Destination, and Tail Number.  It is necessary to not limit ourselves to only the top ten of any of these options because these will be unique entries by the user later when the model is being implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform get_dummies method on the OP_Carrier and Departure Time Blocks columns\n",
    "dummy_columns = ['OP_CARRIER']\n",
    "prefix = ['Carrier']\n",
    "dummy_df = pd.get_dummies(machine_model_df[dummy_columns], prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranform each column with LabelEncoder (https://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn)\n",
    "lableEncoder_columns = ['ORIGIN', 'DEST']  #, 'TAIL_NUM'\n",
    "d = defaultdict(LabelEncoder)\n",
    "\n",
    "df = machine_model_df[lableEncoder_columns]\n",
    "\n",
    "# Encoding the variable\n",
    "labelEncoded_df = df.apply(lambda x: d[x.name].fit_transform(x))\n",
    "\n",
    "# Retaining this code here for later reference\n",
    "## Inverse the encoded\n",
    "# fit.apply(lambda x: d[x.name].inverse_transform(x))\n",
    "\n",
    "## Using the dictionary to label future data\n",
    "# df.apply(lambda x: d[x.name].transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>DEP_DEL15</th>\n",
       "      <th>DEP_Hour</th>\n",
       "      <th>windspeedKmph</th>\n",
       "      <th>precipMM</th>\n",
       "      <th>Carrier_9E</th>\n",
       "      <th>Carrier_AA</th>\n",
       "      <th>Carrier_AS</th>\n",
       "      <th>Carrier_B6</th>\n",
       "      <th>Carrier_DL</th>\n",
       "      <th>...</th>\n",
       "      <th>Carrier_MQ</th>\n",
       "      <th>Carrier_NK</th>\n",
       "      <th>Carrier_OH</th>\n",
       "      <th>Carrier_OO</th>\n",
       "      <th>Carrier_UA</th>\n",
       "      <th>Carrier_WN</th>\n",
       "      <th>Carrier_YV</th>\n",
       "      <th>Carrier_YX</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    DAY_OF_WEEK  DEP_DEL15  DEP_Hour  windspeedKmph  precipMM  Carrier_9E  \\\n",
       "2             2          0        13           10.0       0.0           1   \n",
       "4             2          0        12           21.0       0.0           1   \n",
       "8             2          0        18           10.0       2.4           1   \n",
       "14            2          0        15           19.0       0.1           1   \n",
       "18            2          0        12           12.0       0.1           1   \n",
       "\n",
       "    Carrier_AA  Carrier_AS  Carrier_B6  Carrier_DL  ...  Carrier_MQ  \\\n",
       "2            0           0           0           0  ...           0   \n",
       "4            0           0           0           0  ...           0   \n",
       "8            0           0           0           0  ...           0   \n",
       "14           0           0           0           0  ...           0   \n",
       "18           0           0           0           0  ...           0   \n",
       "\n",
       "    Carrier_NK  Carrier_OH  Carrier_OO  Carrier_UA  Carrier_WN  Carrier_YV  \\\n",
       "2            0           0           0           0           0           0   \n",
       "4            0           0           0           0           0           0   \n",
       "8            0           0           0           0           0           0   \n",
       "14           0           0           0           0           0           0   \n",
       "18           0           0           0           0           0           0   \n",
       "\n",
       "    Carrier_YX  ORIGIN  DEST  \n",
       "2            0      29    77  \n",
       "4            0      13    77  \n",
       "8            0       0   116  \n",
       "14           0      24    77  \n",
       "18           0       0    37  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the encoded columns\n",
    "machine_model_df_encoded = machine_model_df.drop(flights_cat, axis=1)\n",
    "machine_model_df_encoded = pd.concat([machine_model_df_encoded, dummy_df, labelEncoded_df], axis = 1)\n",
    "machine_model_df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DEP_DEL15\n",
       "0    768487\n",
       "1    142390\n",
       "dtype: int64"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine_model_df_encoded.groupby(['DEP_DEL15']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Feature and Target Variables\n",
    "y = machine_model_df_encoded[\"DEP_DEL15\"]  # Target\n",
    "X = machine_model_df_encoded.drop(columns=\"DEP_DEL15\") # Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Splitting Data:\n",
    "Using the method imported from the package sklearn, the dataset is split into a training set and a test set.\n",
    "The seperation is achived randomly.  \n",
    "By adding the condition stratify = y, we are insuring that the test and training sets contain the proportion \n",
    "of values as provided in the target set.  By setting random_state to a specific value we can get repeatedly the same split of the data so it is possible to make sure that at least the testing and training sets are consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683157, 23)"
      ]
     },
     "execution_count": 758,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=34, \n",
    "                                                    stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess numerical data\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Multiple models were evaluated to determine how well they are able to predict the end result.  It is important to note that there are far fewer delayed flights than flights that are on time.  Because that is true, when evaluating how accurate the model is at predicting we will need to evaluate it using precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Logistic Regression Model\n",
    "classifier = LogisticRegression(solver='lbfgs',\n",
    "                                max_iter=2000,\n",
    "                                random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=2000, random_state=10)"
      ]
     },
     "execution_count": 761,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prediction  Actual\n",
       "0            0       0\n",
       "1            0       0\n",
       "2            0       0\n",
       "3            0       0\n",
       "4            0       0\n",
       "5            0       0\n",
       "6            0       0\n",
       "7            0       0\n",
       "8            0       0\n",
       "9            0       0\n",
       "10           0       0\n",
       "11           0       0\n",
       "12           0       0\n",
       "13           0       1\n",
       "14           0       0\n",
       "15           0       0\n",
       "16           0       0\n",
       "17           0       0\n",
       "18           0       0\n",
       "19           0       0"
      ]
     },
     "execution_count": 762,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions \n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[192059,     63],\n",
       "       [ 35561,     37]], dtype=int64)"
      ]
     },
     "execution_count": 763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.92    192122\n",
      "           1       0.37      0.00      0.00     35598\n",
      "\n",
      "    accuracy                           0.84    227720\n",
      "   macro avg       0.61      0.50      0.46    227720\n",
      "weighted avg       0.77      0.84      0.77    227720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Because dataset is imbalanced we cant use accuracy metric\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dt = DecisionTreeClassifier(random_state = 0)\n",
    "model_dt = clf_dt.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88    192122\n",
      "           1       0.35      0.35      0.35     35598\n",
      "\n",
      "    accuracy                           0.80    227720\n",
      "   macro avg       0.62      0.62      0.62    227720\n",
      "weighted avg       0.80      0.80      0.80    227720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_dt.predict(X_test_scaled)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[169123,  22999],\n",
       "       [ 23114,  12484]], dtype=int64)"
      ]
     },
     "execution_count": 767,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prediction  Actual\n",
       "0            0       0\n",
       "1            1       0\n",
       "2            0       0\n",
       "3            1       0\n",
       "4            0       0\n",
       "5            0       0\n",
       "6            1       0\n",
       "7            0       0\n",
       "8            1       0\n",
       "9            0       0\n",
       "10           0       0\n",
       "11           0       0\n",
       "12           1       0\n",
       "13           1       1\n",
       "14           0       0\n",
       "15           0       0\n",
       "16           0       0\n",
       "17           0       0\n",
       "18           0       0\n",
       "19           0       0"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier\n",
    "This one is too slow and is demonstrated to be a poor predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier(max_depth=20)\n",
    "model_rf = clf_rf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92    192122\n",
      "           1       0.80      0.07      0.13     35598\n",
      "\n",
      "    accuracy                           0.85    227720\n",
      "   macro avg       0.82      0.53      0.52    227720\n",
      "weighted avg       0.84      0.85      0.79    227720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_rf.predict(X_test_scaled)\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[191500,    622],\n",
       "       [ 33166,   2432]], dtype=int64)"
      ]
     },
     "execution_count": 774,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Class label 2 not present.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-779-9702c20f5a91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             verbose=0, warm_start=False)\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mmodel_rdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_y_class_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mDOUBLE\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_y_class_weight\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    602\u001b[0m                     \u001b[0mclass_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m                 expanded_class_weight = compute_sample_weight(class_weight,\n\u001b[1;32m--> 604\u001b[1;33m                                                               y_original)\n\u001b[0m\u001b[0;32m    605\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\class_weight.py\u001b[0m in \u001b[0;36mcompute_sample_weight\u001b[1;34m(class_weight, y, indices)\u001b[0m\n\u001b[0;32m    165\u001b[0m             weight_k = compute_class_weight(class_weight_k,\n\u001b[0;32m    166\u001b[0m                                             \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclasses_full\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m                                             y=y_full)\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[0mweight_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweight_k\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses_full\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_full\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\class_weight.py\u001b[0m in \u001b[0;36mcompute_class_weight\u001b[1;34m(class_weight, classes, y)\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Class label {} not present.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[0mweight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Class label 2 not present."
     ]
    }
   ],
   "source": [
    "class_weight = dict({1:1, 2:6})\n",
    "rdf = RandomForestClassifier(bootstrap=True,\n",
    "            class_weight=class_weight, \n",
    "            criterion='gini',\n",
    "            max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=4, min_samples_split=10,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=300,\n",
    "            oob_score=False,\n",
    "            random_state=0,\n",
    "            verbose=0, warm_start=False)\n",
    "model_rdf = rdf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "27311/27311 [==============================] - 18s 668us/step - loss: 0.4174 - accuracy: 0.8453\n",
      "Epoch 2/100\n",
      "27311/27311 [==============================] - 18s 662us/step - loss: 0.4140 - accuracy: 0.8457\n",
      "Epoch 3/100\n",
      "27311/27311 [==============================] - 18s 676us/step - loss: 0.4127 - accuracy: 0.8457\n",
      "Epoch 4/100\n",
      "27311/27311 [==============================] - 19s 681us/step - loss: 0.4119 - accuracy: 0.8457\n",
      "Epoch 5/100\n",
      "27311/27311 [==============================] - 18s 652us/step - loss: 0.4110 - accuracy: 0.8457\n",
      "Epoch 6/100\n",
      "27311/27311 [==============================] - 19s 701us/step - loss: 0.4102 - accuracy: 0.8457\n",
      "Epoch 7/100\n",
      "27311/27311 [==============================] - 21s 757us/step - loss: 0.4096 - accuracy: 0.8457\n",
      "Epoch 8/100\n",
      "27311/27311 [==============================] - 18s 671us/step - loss: 0.4091 - accuracy: 0.8457\n",
      "Epoch 9/100\n",
      "27311/27311 [==============================] - 18s 661us/step - loss: 0.4088 - accuracy: 0.8457\n",
      "Epoch 10/100\n",
      "27311/27311 [==============================] - 18s 650us/step - loss: 0.4084 - accuracy: 0.8458\n",
      "Epoch 11/100\n",
      "27311/27311 [==============================] - 17s 638us/step - loss: 0.4082 - accuracy: 0.8458\n",
      "Epoch 12/100\n",
      "27311/27311 [==============================] - 19s 687us/step - loss: 0.4080 - accuracy: 0.8458\n",
      "Epoch 13/100\n",
      "27311/27311 [==============================] - 18s 662us/step - loss: 0.4078 - accuracy: 0.8458\n",
      "Epoch 14/100\n",
      "27311/27311 [==============================] - 18s 655us/step - loss: 0.4076 - accuracy: 0.8458\n",
      "Epoch 15/100\n",
      "27311/27311 [==============================] - 18s 651us/step - loss: 0.4075 - accuracy: 0.8458\n",
      "Epoch 16/100\n",
      "27311/27311 [==============================] - 18s 641us/step - loss: 0.4073 - accuracy: 0.8458\n",
      "Epoch 17/100\n",
      "27311/27311 [==============================] - 18s 658us/step - loss: 0.4071 - accuracy: 0.8458\n",
      "Epoch 18/100\n",
      "27311/27311 [==============================] - 18s 672us/step - loss: 0.4071 - accuracy: 0.8458\n",
      "Epoch 19/100\n",
      "27311/27311 [==============================] - 18s 668us/step - loss: 0.4069 - accuracy: 0.8459\n",
      "Epoch 20/100\n",
      "27311/27311 [==============================] - 19s 706us/step - loss: 0.4067 - accuracy: 0.8458\n",
      "Epoch 21/100\n",
      "27311/27311 [==============================] - 18s 671us/step - loss: 0.4067 - accuracy: 0.8459\n",
      "Epoch 22/100\n",
      "27311/27311 [==============================] - 19s 696us/step - loss: 0.4066 - accuracy: 0.8459\n",
      "Epoch 23/100\n",
      "27311/27311 [==============================] - 18s 666us/step - loss: 0.4064 - accuracy: 0.8459\n",
      "Epoch 24/100\n",
      "27311/27311 [==============================] - 18s 651us/step - loss: 0.4064 - accuracy: 0.8459\n",
      "Epoch 25/100\n",
      "27311/27311 [==============================] - 19s 701us/step - loss: 0.4063 - accuracy: 0.8459\n",
      "Epoch 26/100\n",
      "27311/27311 [==============================] - 18s 649us/step - loss: 0.4063 - accuracy: 0.8459\n",
      "Epoch 27/100\n",
      "27311/27311 [==============================] - 18s 652us/step - loss: 0.4062 - accuracy: 0.8458\n",
      "Epoch 28/100\n",
      "27311/27311 [==============================] - 18s 664us/step - loss: 0.4061 - accuracy: 0.8459\n",
      "Epoch 29/100\n",
      "27311/27311 [==============================] - 18s 660us/step - loss: 0.4061 - accuracy: 0.8459\n",
      "Epoch 30/100\n",
      "27311/27311 [==============================] - 18s 674us/step - loss: 0.4061 - accuracy: 0.8459\n",
      "Epoch 31/100\n",
      "27311/27311 [==============================] - 19s 698us/step - loss: 0.4059 - accuracy: 0.8458\n",
      "Epoch 32/100\n",
      "27311/27311 [==============================] - 19s 685us/step - loss: 0.4059 - accuracy: 0.8459\n",
      "Epoch 33/100\n",
      "27311/27311 [==============================] - 19s 680us/step - loss: 0.4060 - accuracy: 0.8459\n",
      "Epoch 34/100\n",
      "27311/27311 [==============================] - 19s 700us/step - loss: 0.4058 - accuracy: 0.8459\n",
      "Epoch 35/100\n",
      "27311/27311 [==============================] - 19s 698us/step - loss: 0.4058 - accuracy: 0.8459\n",
      "Epoch 36/100\n",
      "27311/27311 [==============================] - 19s 706us/step - loss: 0.4058 - accuracy: 0.8459\n",
      "Epoch 37/100\n",
      "27311/27311 [==============================] - 20s 722us/step - loss: 0.4057 - accuracy: 0.8459\n",
      "Epoch 38/100\n",
      "27311/27311 [==============================] - 18s 667us/step - loss: 0.4056 - accuracy: 0.8459\n",
      "Epoch 39/100\n",
      "27311/27311 [==============================] - 18s 665us/step - loss: 0.4056 - accuracy: 0.8458\n",
      "Epoch 40/100\n",
      "27311/27311 [==============================] - 18s 673us/step - loss: 0.4056 - accuracy: 0.8459\n",
      "Epoch 41/100\n",
      "27311/27311 [==============================] - 18s 661us/step - loss: 0.4055 - accuracy: 0.8460\n",
      "Epoch 42/100\n",
      "27311/27311 [==============================] - 18s 664us/step - loss: 0.4055 - accuracy: 0.8459\n",
      "Epoch 43/100\n",
      "27311/27311 [==============================] - 18s 673us/step - loss: 0.4054 - accuracy: 0.8460\n",
      "Epoch 44/100\n",
      "27311/27311 [==============================] - 19s 680us/step - loss: 0.4053 - accuracy: 0.8459\n",
      "Epoch 45/100\n",
      "27311/27311 [==============================] - 19s 713us/step - loss: 0.4054 - accuracy: 0.8459\n",
      "Epoch 46/100\n",
      "27311/27311 [==============================] - 18s 669us/step - loss: 0.4054 - accuracy: 0.8459\n",
      "Epoch 47/100\n",
      "27311/27311 [==============================] - 19s 682us/step - loss: 0.4053 - accuracy: 0.8459\n",
      "Epoch 48/100\n",
      "27311/27311 [==============================] - 18s 669us/step - loss: 0.4052 - accuracy: 0.8459\n",
      "Epoch 49/100\n",
      "27311/27311 [==============================] - 18s 660us/step - loss: 0.4053 - accuracy: 0.8459\n",
      "Epoch 50/100\n",
      "27311/27311 [==============================] - 19s 699us/step - loss: 0.4052 - accuracy: 0.8459\n",
      "Epoch 51/100\n",
      "27311/27311 [==============================] - 18s 672us/step - loss: 0.4052 - accuracy: 0.8459\n",
      "Epoch 52/100\n",
      "27311/27311 [==============================] - 18s 672us/step - loss: 0.4052 - accuracy: 0.8459\n",
      "Epoch 53/100\n",
      "27311/27311 [==============================] - 18s 658us/step - loss: 0.4051 - accuracy: 0.8460\n",
      "Epoch 54/100\n",
      "27311/27311 [==============================] - 18s 666us/step - loss: 0.4051 - accuracy: 0.8460\n",
      "Epoch 55/100\n",
      "27311/27311 [==============================] - 19s 690us/step - loss: 0.4051 - accuracy: 0.8460\n",
      "Epoch 56/100\n",
      "27311/27311 [==============================] - 19s 689us/step - loss: 0.4052 - accuracy: 0.8460\n",
      "Epoch 57/100\n",
      "27311/27311 [==============================] - 19s 694us/step - loss: 0.4050 - accuracy: 0.8460\n",
      "Epoch 58/100\n",
      "27311/27311 [==============================] - 19s 700us/step - loss: 0.4051 - accuracy: 0.8459\n",
      "Epoch 59/100\n",
      "27311/27311 [==============================] - 19s 678us/step - loss: 0.4050 - accuracy: 0.8459\n",
      "Epoch 60/100\n",
      "27311/27311 [==============================] - 18s 677us/step - loss: 0.4050 - accuracy: 0.8460\n",
      "Epoch 61/100\n",
      "27311/27311 [==============================] - 19s 683us/step - loss: 0.4050 - accuracy: 0.8459\n",
      "Epoch 62/100\n",
      "27311/27311 [==============================] - 18s 675us/step - loss: 0.4049 - accuracy: 0.8459\n",
      "Epoch 63/100\n",
      "27311/27311 [==============================] - 19s 709us/step - loss: 0.4049 - accuracy: 0.8460\n",
      "Epoch 64/100\n",
      "27311/27311 [==============================] - 20s 727us/step - loss: 0.4049 - accuracy: 0.8461\n",
      "Epoch 65/100\n",
      "27311/27311 [==============================] - 18s 677us/step - loss: 0.4049 - accuracy: 0.8460\n",
      "Epoch 66/100\n",
      "27311/27311 [==============================] - 18s 670us/step - loss: 0.4050 - accuracy: 0.8460\n",
      "Epoch 67/100\n",
      "27311/27311 [==============================] - 18s 676us/step - loss: 0.4048 - accuracy: 0.8460\n",
      "Epoch 68/100\n",
      "27311/27311 [==============================] - 18s 671us/step - loss: 0.4048 - accuracy: 0.8460\n",
      "Epoch 69/100\n",
      "27311/27311 [==============================] - 19s 678us/step - loss: 0.4048 - accuracy: 0.8460\n",
      "Epoch 70/100\n",
      "27311/27311 [==============================] - 19s 678us/step - loss: 0.4048 - accuracy: 0.8460\n",
      "Epoch 71/100\n",
      "27311/27311 [==============================] - 19s 681us/step - loss: 0.4048 - accuracy: 0.8460\n",
      "Epoch 72/100\n",
      "27311/27311 [==============================] - 19s 682us/step - loss: 0.4048 - accuracy: 0.8461\n",
      "Epoch 73/100\n",
      "27311/27311 [==============================] - 19s 680us/step - loss: 0.4048 - accuracy: 0.8461\n",
      "Epoch 74/100\n",
      "27311/27311 [==============================] - 19s 704us/step - loss: 0.4048 - accuracy: 0.8461\n",
      "Epoch 75/100\n",
      "27311/27311 [==============================] - 19s 703us/step - loss: 0.4048 - accuracy: 0.8460\n",
      "Epoch 76/100\n",
      "27311/27311 [==============================] - 18s 677us/step - loss: 0.4048 - accuracy: 0.8460\n",
      "Epoch 77/100\n",
      "27311/27311 [==============================] - 18s 645us/step - loss: 0.4047 - accuracy: 0.8460\n",
      "Epoch 78/100\n",
      "27311/27311 [==============================] - 16s 599us/step - loss: 0.4047 - accuracy: 0.8461\n",
      "Epoch 79/100\n",
      "27311/27311 [==============================] - 16s 600us/step - loss: 0.4047 - accuracy: 0.8460\n",
      "Epoch 80/100\n",
      "27311/27311 [==============================] - 16s 604us/step - loss: 0.4047 - accuracy: 0.8460\n",
      "Epoch 81/100\n",
      "27311/27311 [==============================] - 16s 600us/step - loss: 0.4046 - accuracy: 0.8461\n",
      "Epoch 82/100\n",
      "27311/27311 [==============================] - 17s 604us/step - loss: 0.4046 - accuracy: 0.8461\n",
      "Epoch 83/100\n",
      "27311/27311 [==============================] - 17s 620us/step - loss: 0.4046 - accuracy: 0.8461\n",
      "Epoch 84/100\n",
      "27311/27311 [==============================] - 16s 600us/step - loss: 0.4046 - accuracy: 0.8461\n",
      "Epoch 85/100\n",
      "27311/27311 [==============================] - 16s 597us/step - loss: 0.4046 - accuracy: 0.8461\n",
      "Epoch 86/100\n",
      "27311/27311 [==============================] - 17s 616us/step - loss: 0.4046 - accuracy: 0.8461\n",
      "Epoch 87/100\n",
      "27311/27311 [==============================] - 17s 627us/step - loss: 0.4046 - accuracy: 0.8461\n",
      "Epoch 88/100\n",
      "27311/27311 [==============================] - 16s 600us/step - loss: 0.4045 - accuracy: 0.8461\n",
      "Epoch 89/100\n",
      "27311/27311 [==============================] - 16s 595us/step - loss: 0.4045 - accuracy: 0.8461\n",
      "Epoch 90/100\n",
      "27311/27311 [==============================] - 16s 604us/step - loss: 0.4045 - accuracy: 0.8461\n",
      "Epoch 91/100\n",
      "27311/27311 [==============================] - 16s 602us/step - loss: 0.4045 - accuracy: 0.8461\n",
      "Epoch 92/100\n",
      "27311/27311 [==============================] - 16s 601us/step - loss: 0.4045 - accuracy: 0.8461\n",
      "Epoch 93/100\n",
      "27311/27311 [==============================] - 16s 599us/step - loss: 0.4044 - accuracy: 0.8461\n",
      "Epoch 94/100\n",
      "27311/27311 [==============================] - 16s 600us/step - loss: 0.4044 - accuracy: 0.8461\n",
      "Epoch 95/100\n",
      "27311/27311 [==============================] - 16s 600us/step - loss: 0.4042 - accuracy: 0.8461\n",
      "Epoch 96/100\n",
      "27311/27311 [==============================] - 16s 598us/step - loss: 0.4041 - accuracy: 0.8461\n",
      "Epoch 97/100\n",
      "27311/27311 [==============================] - 16s 600us/step - loss: 0.4041 - accuracy: 0.8460\n",
      "Epoch 98/100\n",
      "27311/27311 [==============================] - 17s 604us/step - loss: 0.4041 - accuracy: 0.8461\n",
      "Epoch 99/100\n",
      "27311/27311 [==============================] - 16s 601us/step - loss: 0.4040 - accuracy: 0.8461\n",
      "Epoch 100/100\n",
      "27311/27311 [==============================] - 16s 601us/step - loss: 0.4039 - accuracy: 0.8462\n",
      "9104/9104 - 4s - loss: 0.4080 - accuracy: 0.8458\n",
      "Loss: 0.4080069363117218, Accuracy: 0.8458263874053955\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 =  1.5 * len(X_train_scaled[0])\n",
    "hidden_nodes_layer2 = 12\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Predictions\n",
    "y_pred = tf.round(nn.predict(X_test_scaled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92    246370\n",
      "           1       0.52      0.01      0.01     44938\n",
      "\n",
      "    accuracy                           0.85    291308\n",
      "   macro avg       0.68      0.50      0.47    291308\n",
      "weighted avg       0.80      0.85      0.78    291308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[246083,    287],\n",
       "       [ 44625,    313]], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Final Selection\n",
    "After evaluating each model using the entire combined dataset, it was found that Decision Tree was the best at predicting delays.  That will be the model we will use going forward."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
