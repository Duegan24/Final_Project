{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "from path import Path\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from collections import defaultdict\n",
    "import pickle, os\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary data preprocessing\n",
    "Original Dataset was provided by a Kaggle Project.  For the intial analysis of the dataset the information was imported to a local directory and then imported read into this jupyter notebook.  Later we will have the connection to the database here. The dataset already came as a csv file so no further processing was necessary.  \n",
    "\n",
    "Merging of the weather data was accomplished by using the World Weather Online API.  The download of the required information was achieved in a seperate jupyter notebook.  Data was formated as a simple csv file and was imported below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>OP_CARRIER_AIRLINE_ID</th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN_AIRPORT_ID</th>\n",
       "      <th>ORIGIN_AIRPORT_SEQ_ID</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST_AIRPORT_ID</th>\n",
       "      <th>DEST_AIRPORT_SEQ_ID</th>\n",
       "      <th>DEST</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DEL15</th>\n",
       "      <th>DEP_TIME_BLK</th>\n",
       "      <th>ARR_TIME</th>\n",
       "      <th>ARR_DEL15</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>DISTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20363</td>\n",
       "      <td>9E</td>\n",
       "      <td>N8688C</td>\n",
       "      <td>3280</td>\n",
       "      <td>11953</td>\n",
       "      <td>1195302</td>\n",
       "      <td>GNV</td>\n",
       "      <td>10397</td>\n",
       "      <td>1039707</td>\n",
       "      <td>ATL</td>\n",
       "      <td>601.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0600-0659</td>\n",
       "      <td>722.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20363</td>\n",
       "      <td>9E</td>\n",
       "      <td>N348PQ</td>\n",
       "      <td>3281</td>\n",
       "      <td>13487</td>\n",
       "      <td>1348702</td>\n",
       "      <td>MSP</td>\n",
       "      <td>11193</td>\n",
       "      <td>1119302</td>\n",
       "      <td>CVG</td>\n",
       "      <td>1359.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1400-1459</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20363</td>\n",
       "      <td>9E</td>\n",
       "      <td>N8896A</td>\n",
       "      <td>3282</td>\n",
       "      <td>11433</td>\n",
       "      <td>1143302</td>\n",
       "      <td>DTW</td>\n",
       "      <td>11193</td>\n",
       "      <td>1119302</td>\n",
       "      <td>CVG</td>\n",
       "      <td>1215.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1200-1259</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20363</td>\n",
       "      <td>9E</td>\n",
       "      <td>N8886A</td>\n",
       "      <td>3283</td>\n",
       "      <td>15249</td>\n",
       "      <td>1524906</td>\n",
       "      <td>TLH</td>\n",
       "      <td>10397</td>\n",
       "      <td>1039707</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1521.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500-1559</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20363</td>\n",
       "      <td>9E</td>\n",
       "      <td>N8974C</td>\n",
       "      <td>3284</td>\n",
       "      <td>10397</td>\n",
       "      <td>1039707</td>\n",
       "      <td>ATL</td>\n",
       "      <td>11778</td>\n",
       "      <td>1177801</td>\n",
       "      <td>FSM</td>\n",
       "      <td>1847.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1900-1959</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DAY_OF_MONTH  DAY_OF_WEEK  OP_CARRIER_AIRLINE_ID OP_CARRIER TAIL_NUM  \\\n",
       "0             1            2                  20363         9E   N8688C   \n",
       "1             1            2                  20363         9E   N348PQ   \n",
       "2             1            2                  20363         9E   N8896A   \n",
       "3             1            2                  20363         9E   N8886A   \n",
       "4             1            2                  20363         9E   N8974C   \n",
       "\n",
       "   OP_CARRIER_FL_NUM  ORIGIN_AIRPORT_ID  ORIGIN_AIRPORT_SEQ_ID ORIGIN  \\\n",
       "0               3280              11953                1195302    GNV   \n",
       "1               3281              13487                1348702    MSP   \n",
       "2               3282              11433                1143302    DTW   \n",
       "3               3283              15249                1524906    TLH   \n",
       "4               3284              10397                1039707    ATL   \n",
       "\n",
       "   DEST_AIRPORT_ID  DEST_AIRPORT_SEQ_ID DEST  DEP_TIME  DEP_DEL15  \\\n",
       "0            10397              1039707  ATL     601.0        0.0   \n",
       "1            11193              1119302  CVG    1359.0        0.0   \n",
       "2            11193              1119302  CVG    1215.0        0.0   \n",
       "3            10397              1039707  ATL    1521.0        0.0   \n",
       "4            11778              1177801  FSM    1847.0        0.0   \n",
       "\n",
       "  DEP_TIME_BLK  ARR_TIME  ARR_DEL15  CANCELLED  DIVERTED  DISTANCE  \n",
       "0    0600-0659     722.0        0.0          0         0       300  \n",
       "1    1400-1459    1633.0        0.0          0         0       596  \n",
       "2    1200-1259    1329.0        0.0          0         0       229  \n",
       "3    1500-1559    1625.0        0.0          0         0       223  \n",
       "4    1900-1959    1940.0        0.0          0         0       579  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import testing dataset\n",
    "flights_2019 = pd.read_csv('Database/Data/jan_19_clean_data.csv')\n",
    "flights_2020 = pd.read_csv('Database/Data/jan_20_clean_data.csv')\n",
    "\n",
    "flights_2019.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Feature Engineering\n",
    "Beyond a visual inspection of the head of the data the following steps were performed below:\n",
    "\n",
    "1) Determined if there are any rows that need to be dropped because they are missing data.\n",
    "\n",
    "2) Determine which columns of data will need to be included in the training set.\n",
    "\n",
    "3) Perform the inital encoding of the columns that contained objects as numerical values so it would be easier for the machine learning model to process it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows with missing information from 2019 data was:   0\n"
     ]
    }
   ],
   "source": [
    "na_count = flights_2019.DAY_OF_MONTH.count() - flights_2019.dropna(axis=0).DAY_OF_MONTH.count()\n",
    "print('Total rows with missing information from 2019 data was:  ', na_count )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows with missing information from 2019 data was:   0\n"
     ]
    }
   ],
   "source": [
    "na_count = flights_2020.DAY_OF_MONTH.count() - flights_2020.dropna(axis=0).DAY_OF_MONTH.count()\n",
    "print('Total rows with missing information from 2019 data was:  ', na_count )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step one complete.  The datasets are already cleaned with no missing information in any of the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two data sets to give more data for the model to work with\n",
    "flights = pd.concat([flights_2019, flights_2020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DAY_OF_MONTH', 'DAY_OF_WEEK', 'OP_CARRIER_AIRLINE_ID', 'OP_CARRIER',\n",
       "       'TAIL_NUM', 'OP_CARRIER_FL_NUM', 'ORIGIN_AIRPORT_ID',\n",
       "       'ORIGIN_AIRPORT_SEQ_ID', 'ORIGIN', 'DEST_AIRPORT_ID',\n",
       "       'DEST_AIRPORT_SEQ_ID', 'DEST', 'DEP_TIME', 'DEP_DEL15', 'DEP_TIME_BLK',\n",
       "       'ARR_TIME', 'ARR_DEL15', 'CANCELLED', 'DIVERTED', 'DISTANCE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Look at the available columns\n",
    "flights.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:\n",
    "#### Feature Selection:\n",
    "\n",
    "To determine which features to include it was important to determine how we want to use the predictive model.\n",
    "In this case we will be taking a set of inputs from the user and displaying which time slot is most likely to not\n",
    "have a flight delay. So we will only include information the model that we can get from the user or provide look up tables for.\n",
    "\n",
    "The filterdList below included all the data that we either we will be able to get from the user, will be a look up\n",
    "or is the primary feature we want to predict. \n",
    "\n",
    "In this case it is whether there will be a departure delay or not the column name DEP_DEL15 will the be feature we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>DEP_DEL15</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>DEP_TIME_BLK</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9E</td>\n",
       "      <td>GNV</td>\n",
       "      <td>ATL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "      <td>0600-0659</td>\n",
       "      <td>N8688C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9E</td>\n",
       "      <td>MSP</td>\n",
       "      <td>CVG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>596</td>\n",
       "      <td>1400-1459</td>\n",
       "      <td>N348PQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9E</td>\n",
       "      <td>DTW</td>\n",
       "      <td>CVG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229</td>\n",
       "      <td>1200-1259</td>\n",
       "      <td>N8896A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9E</td>\n",
       "      <td>TLH</td>\n",
       "      <td>ATL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223</td>\n",
       "      <td>1500-1559</td>\n",
       "      <td>N8886A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9E</td>\n",
       "      <td>ATL</td>\n",
       "      <td>FSM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>579</td>\n",
       "      <td>1900-1959</td>\n",
       "      <td>N8974C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DAY_OF_MONTH  DAY_OF_WEEK OP_CARRIER ORIGIN DEST  DEP_DEL15  DISTANCE  \\\n",
       "0             1            2         9E    GNV  ATL        0.0       300   \n",
       "1             1            2         9E    MSP  CVG        0.0       596   \n",
       "2             1            2         9E    DTW  CVG        0.0       229   \n",
       "3             1            2         9E    TLH  ATL        0.0       223   \n",
       "4             1            2         9E    ATL  FSM        0.0       579   \n",
       "\n",
       "  DEP_TIME_BLK TAIL_NUM  \n",
       "0    0600-0659   N8688C  \n",
       "1    1400-1459   N348PQ  \n",
       "2    1200-1259   N8896A  \n",
       "3    1500-1559   N8886A  \n",
       "4    1900-1959   N8974C  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the list that we are going to keep as features\n",
    "filteredList = ['DAY_OF_MONTH', 'DAY_OF_WEEK', 'OP_CARRIER', 'ORIGIN', 'DEST', 'DEP_DEL15', 'DISTANCE'\n",
    "                ,'DEP_TIME_BLK', 'TAIL_NUM']\n",
    "\n",
    "# Keep the list of columns that were removed...possibly for later use.\n",
    "columnsRemoved = ['OP_CARRIER_AIRLINE_ID', 'DEST_AIRPORT_SEQ_ID', 'ORIGIN_AIRPORT_SEQ_ID' , 'ORIGIN_AIRPORT_ID'\n",
    "                  , 'OP_CARRIER_FL_NUM', 'DEST_AIRPORT_ID', 'ARR_TIME', 'ARR_DEL15', 'CANCELLED', 'DIVERTED', 'DEP_TIME']\n",
    "\n",
    "# Filter the data to only include the columns we want\n",
    "machine_model_df = flights.filter(filteredList)\n",
    "machine_model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the feature we want to predict as a integer since on import it was made a float\n",
    "machine_model_df.DEP_DEL15 = machine_model_df.DEP_DEL15.astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are evaluating the impact of including Departure Time and a floating number in the dataset.\n",
    "# if it is there then make it an integer\n",
    "if \"DEP_TIME\" in machine_model_df.columns:\n",
    "    machine_model_df.DEP_TIME = machine_model_df.DEP_TIME.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAY_OF_MONTH     int64\n",
       "DAY_OF_WEEK      int64\n",
       "OP_CARRIER      object\n",
       "ORIGIN          object\n",
       "DEST            object\n",
       "DEP_DEL15        int32\n",
       "DISTANCE         int64\n",
       "DEP_TIME_BLK    object\n",
       "TAIL_NUM        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine features and determine how the various features will need to be encoded\n",
    "machine_model_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OP_CARRIER        17\n",
       "ORIGIN           353\n",
       "DEST             353\n",
       "DEP_TIME_BLK      19\n",
       "TAIL_NUM        5854\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate our categorical variable list\n",
    "flights_cat = machine_model_df.dtypes[machine_model_df.dtypes == \"object\"].index.tolist()\n",
    "\n",
    "# Check the number of unique values in each column\n",
    "machine_model_df[flights_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records:   1165231\n",
      "Total number of columns:   9\n"
     ]
    }
   ],
   "source": [
    "# Evaluate how many records are available in the dataset\n",
    "print('Total number of records:  ', machine_model_df.DAY_OF_MONTH.count())\n",
    "print('Total number of columns:  ', len(machine_model_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 2 - Encoding:\n",
    "#### Encoding Method:\n",
    "A couple of things to note, the complete dataset has over a million records and there are currently 9 columns.  Given the number of columns that have unique string data, to attempt to apply get_dummies would dramatically increase the datatable size.  This was attempted on the Carrier and Origin the result was a error code stating that there was inadequate resources.  \n",
    "\n",
    "We will reserve the get_dummy encoding method for the OP_Carrier and Departure Time Blocks only and will use LabelEncoder for Origin, Destination, and Tail Number.  It is necessary to not limit ourselves to only the top ten of any of these options because these will be unique entries by the user later when the model is being implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform get_dummies method on the OP_Carrier and Departure Time Blocks columns\n",
    "dummy_columns = ['OP_CARRIER', 'DEP_TIME_BLK']\n",
    "prefix = ['Carrier', 'Time_Block']\n",
    "dummy_df = pd.get_dummies(machine_model_df[dummy_columns], prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranform each column with LabelEncoder (https://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn)\n",
    "lableEncoder_columns = ['ORIGIN', 'DEST', 'TAIL_NUM']\n",
    "d = defaultdict(LabelEncoder)\n",
    "\n",
    "df = machine_model_df[lableEncoder_columns]\n",
    "\n",
    "# Encoding the variable\n",
    "labelEncoded_df = df.apply(lambda x: d[x.name].fit_transform(x))\n",
    "\n",
    "# Retaining this code here for later reference\n",
    "## Inverse the encoded\n",
    "# fit.apply(lambda x: d[x.name].inverse_transform(x))\n",
    "\n",
    "## Using the dictionary to label future data\n",
    "# df.apply(lambda x: d[x.name].transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>DEP_DEL15</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>Carrier_9E</th>\n",
       "      <th>Carrier_AA</th>\n",
       "      <th>Carrier_AS</th>\n",
       "      <th>Carrier_B6</th>\n",
       "      <th>Carrier_DL</th>\n",
       "      <th>Carrier_EV</th>\n",
       "      <th>...</th>\n",
       "      <th>Time_Block_1700-1759</th>\n",
       "      <th>Time_Block_1800-1859</th>\n",
       "      <th>Time_Block_1900-1959</th>\n",
       "      <th>Time_Block_2000-2059</th>\n",
       "      <th>Time_Block_2100-2159</th>\n",
       "      <th>Time_Block_2200-2259</th>\n",
       "      <th>Time_Block_2300-2359</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>19</td>\n",
       "      <td>4648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>596</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>82</td>\n",
       "      <td>1542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>229</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>82</td>\n",
       "      <td>4810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>331</td>\n",
       "      <td>19</td>\n",
       "      <td>4806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>579</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>122</td>\n",
       "      <td>4867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DAY_OF_MONTH  DAY_OF_WEEK  DEP_DEL15  DISTANCE  Carrier_9E  Carrier_AA  \\\n",
       "0             1            2          0       300           1           0   \n",
       "1             1            2          0       596           1           0   \n",
       "2             1            2          0       229           1           0   \n",
       "3             1            2          0       223           1           0   \n",
       "4             1            2          0       579           1           0   \n",
       "\n",
       "   Carrier_AS  Carrier_B6  Carrier_DL  Carrier_EV  ...  Time_Block_1700-1759  \\\n",
       "0           0           0           0           0  ...                     0   \n",
       "1           0           0           0           0  ...                     0   \n",
       "2           0           0           0           0  ...                     0   \n",
       "3           0           0           0           0  ...                     0   \n",
       "4           0           0           0           0  ...                     0   \n",
       "\n",
       "   Time_Block_1800-1859  Time_Block_1900-1959  Time_Block_2000-2059  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     1                     0   \n",
       "\n",
       "   Time_Block_2100-2159  Time_Block_2200-2259  Time_Block_2300-2359  ORIGIN  \\\n",
       "0                     0                     0                     0     130   \n",
       "1                     0                     0                     0     227   \n",
       "2                     0                     0                     0      97   \n",
       "3                     0                     0                     0     331   \n",
       "4                     0                     0                     0      19   \n",
       "\n",
       "   DEST  TAIL_NUM  \n",
       "0    19      4648  \n",
       "1    82      1542  \n",
       "2    82      4810  \n",
       "3    19      4806  \n",
       "4   122      4867  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the encoded columns\n",
    "machine_model_df_encoded = machine_model_df.drop(flights_cat, axis=1)\n",
    "machine_model_df_encoded = pd.concat([machine_model_df_encoded, dummy_df, labelEncoded_df], axis = 1)\n",
    "machine_model_df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Feature and Target Variables\n",
    "y = machine_model_df_encoded[\"DEP_DEL15\"]  # Target\n",
    "X = machine_model_df_encoded.drop(columns=\"DEP_DEL15\") # Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Splitting Data:\n",
    "Using the method imported from the package sklearn, the dataset is split into a training set and a test set.\n",
    "The seperation is achived randomly.  \n",
    "By adding the condition stratify = y, we are insuring that the test and training sets contain the proportion \n",
    "of values as provided in the target set.  By setting random_state to a specific value we can get repeatedly the same split of the data so it is possible to make sure that at least the testing and training sets are consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(873923, 42)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=34, \n",
    "                                                    stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess numerical data\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Multiple models were evaluated to determine how well they are able to predict the end result.  It is important to note that there are far fewer delayed flights than flights that are on time.  Because that is true, when evaluating how accurate the model is at predicting we will need to evaluate it using precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Logistic Regression Model\n",
    "classifier = LogisticRegression(solver='lbfgs',\n",
    "                                max_iter=2000,\n",
    "                                random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=2000, random_state=10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prediction  Actual\n",
       "0            0       0\n",
       "1            0       0\n",
       "2            0       0\n",
       "3            0       0\n",
       "4            0       0\n",
       "5            0       0\n",
       "6            0       0\n",
       "7            0       0\n",
       "8            0       0\n",
       "9            0       0\n",
       "10           0       0\n",
       "11           0       0\n",
       "12           0       1\n",
       "13           0       0\n",
       "14           0       0\n",
       "15           0       0\n",
       "16           0       0\n",
       "17           0       1\n",
       "18           0       0\n",
       "19           0       1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions \n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[246370,      0],\n",
       "       [ 44938,      0]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjgla\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92    246370\n",
      "           1       0.00      0.00      0.00     44938\n",
      "\n",
      "    accuracy                           0.85    291308\n",
      "   macro avg       0.42      0.50      0.46    291308\n",
      "weighted avg       0.72      0.85      0.78    291308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Because dataset is imbalanced we cant use accuracy metric\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dt = DecisionTreeClassifier(random_state = 0)\n",
    "model_dt = clf_dt.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86    246370\n",
      "           1       0.27      0.29      0.28     44938\n",
      "\n",
      "    accuracy                           0.77    291308\n",
      "   macro avg       0.57      0.57      0.57    291308\n",
      "weighted avg       0.78      0.77      0.77    291308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_dt.predict(X_test_scaled)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[210549,  35821],\n",
       "       [ 31706,  13232]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prediction  Actual\n",
       "0            1       0\n",
       "1            0       0\n",
       "2            0       0\n",
       "3            1       0\n",
       "4            1       0\n",
       "5            0       0\n",
       "6            0       0\n",
       "7            0       0\n",
       "8            0       0\n",
       "9            0       0\n",
       "10           0       0\n",
       "11           0       0\n",
       "12           0       1\n",
       "13           0       0\n",
       "14           0       0\n",
       "15           0       0\n",
       "16           0       0\n",
       "17           0       1\n",
       "18           0       0\n",
       "19           1       1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier\n",
    "This one is too slow and is demonstrated to be a poor predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier(max_depth=10)\n",
    "model_rf = clf_rf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjgla\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92    246370\n",
      "           1       0.00      0.00      0.00     44938\n",
      "\n",
      "    accuracy                           0.85    291308\n",
      "   macro avg       0.42      0.50      0.46    291308\n",
      "weighted avg       0.72      0.85      0.78    291308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_rf.predict(X_test_scaled)\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[246370,      0],\n",
       "       [ 44938,      0]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "27311/27311 [==============================] - 18s 668us/step - loss: 0.4174 - accuracy: 0.8453\n",
      "Epoch 2/100\n",
      "27311/27311 [==============================] - 18s 662us/step - loss: 0.4140 - accuracy: 0.8457\n",
      "Epoch 3/100\n",
      "27311/27311 [==============================] - 18s 676us/step - loss: 0.4127 - accuracy: 0.8457\n",
      "Epoch 4/100\n",
      "27311/27311 [==============================] - 19s 681us/step - loss: 0.4119 - accuracy: 0.8457\n",
      "Epoch 5/100\n",
      "27311/27311 [==============================] - 18s 652us/step - loss: 0.4110 - accuracy: 0.8457\n",
      "Epoch 6/100\n",
      "27311/27311 [==============================] - 19s 701us/step - loss: 0.4102 - accuracy: 0.8457\n",
      "Epoch 7/100\n",
      "27311/27311 [==============================] - 21s 757us/step - loss: 0.4096 - accuracy: 0.8457\n",
      "Epoch 8/100\n",
      "27311/27311 [==============================] - 18s 671us/step - loss: 0.4091 - accuracy: 0.8457\n",
      "Epoch 9/100\n",
      "27311/27311 [==============================] - 18s 661us/step - loss: 0.4088 - accuracy: 0.8457\n",
      "Epoch 10/100\n",
      "27311/27311 [==============================] - 18s 650us/step - loss: 0.4084 - accuracy: 0.8458\n",
      "Epoch 11/100\n",
      "27311/27311 [==============================] - 17s 638us/step - loss: 0.4082 - accuracy: 0.8458\n",
      "Epoch 12/100\n",
      "27311/27311 [==============================] - 19s 687us/step - loss: 0.4080 - accuracy: 0.8458\n",
      "Epoch 13/100\n",
      "27311/27311 [==============================] - 18s 662us/step - loss: 0.4078 - accuracy: 0.8458\n",
      "Epoch 14/100\n",
      "27311/27311 [==============================] - 18s 655us/step - loss: 0.4076 - accuracy: 0.8458\n",
      "Epoch 15/100\n",
      "27311/27311 [==============================] - 18s 651us/step - loss: 0.4075 - accuracy: 0.8458\n",
      "Epoch 16/100\n",
      "27311/27311 [==============================] - 18s 641us/step - loss: 0.4073 - accuracy: 0.8458\n",
      "Epoch 17/100\n",
      "27311/27311 [==============================] - 18s 658us/step - loss: 0.4071 - accuracy: 0.8458\n",
      "Epoch 18/100\n",
      "27311/27311 [==============================] - 18s 672us/step - loss: 0.4071 - accuracy: 0.8458\n",
      "Epoch 19/100\n",
      "27311/27311 [==============================] - 18s 668us/step - loss: 0.4069 - accuracy: 0.8459\n",
      "Epoch 20/100\n",
      "27311/27311 [==============================] - 19s 706us/step - loss: 0.4067 - accuracy: 0.8458\n",
      "Epoch 21/100\n",
      "27311/27311 [==============================] - 18s 671us/step - loss: 0.4067 - accuracy: 0.8459\n",
      "Epoch 22/100\n",
      "27311/27311 [==============================] - 19s 696us/step - loss: 0.4066 - accuracy: 0.8459\n",
      "Epoch 23/100\n",
      "27311/27311 [==============================] - 18s 666us/step - loss: 0.4064 - accuracy: 0.8459\n",
      "Epoch 24/100\n",
      "27311/27311 [==============================] - 18s 651us/step - loss: 0.4064 - accuracy: 0.8459\n",
      "Epoch 25/100\n",
      "27311/27311 [==============================] - 19s 701us/step - loss: 0.4063 - accuracy: 0.8459\n",
      "Epoch 26/100\n",
      "27311/27311 [==============================] - 18s 649us/step - loss: 0.4063 - accuracy: 0.8459\n",
      "Epoch 27/100\n",
      "27311/27311 [==============================] - 18s 652us/step - loss: 0.4062 - accuracy: 0.8458\n",
      "Epoch 28/100\n",
      "27311/27311 [==============================] - 18s 664us/step - loss: 0.4061 - accuracy: 0.8459\n",
      "Epoch 29/100\n",
      "27311/27311 [==============================] - 18s 660us/step - loss: 0.4061 - accuracy: 0.8459\n",
      "Epoch 30/100\n",
      "27311/27311 [==============================] - 18s 674us/step - loss: 0.4061 - accuracy: 0.8459\n",
      "Epoch 31/100\n",
      "27311/27311 [==============================] - 19s 698us/step - loss: 0.4059 - accuracy: 0.8458\n",
      "Epoch 32/100\n",
      "27311/27311 [==============================] - 19s 685us/step - loss: 0.4059 - accuracy: 0.8459\n",
      "Epoch 33/100\n",
      "27311/27311 [==============================] - 19s 680us/step - loss: 0.4060 - accuracy: 0.8459\n",
      "Epoch 34/100\n",
      "27311/27311 [==============================] - 19s 700us/step - loss: 0.4058 - accuracy: 0.8459\n",
      "Epoch 35/100\n",
      "27311/27311 [==============================] - 19s 698us/step - loss: 0.4058 - accuracy: 0.8459\n",
      "Epoch 36/100\n",
      "27311/27311 [==============================] - 19s 706us/step - loss: 0.4058 - accuracy: 0.8459\n",
      "Epoch 37/100\n",
      "27311/27311 [==============================] - 20s 722us/step - loss: 0.4057 - accuracy: 0.8459\n",
      "Epoch 38/100\n",
      "27311/27311 [==============================] - 18s 667us/step - loss: 0.4056 - accuracy: 0.8459\n",
      "Epoch 39/100\n",
      "27311/27311 [==============================] - 18s 665us/step - loss: 0.4056 - accuracy: 0.8458\n",
      "Epoch 40/100\n",
      "27311/27311 [==============================] - 18s 673us/step - loss: 0.4056 - accuracy: 0.8459\n",
      "Epoch 41/100\n",
      "27311/27311 [==============================] - 18s 661us/step - loss: 0.4055 - accuracy: 0.8460\n",
      "Epoch 42/100\n",
      "27311/27311 [==============================] - 18s 664us/step - loss: 0.4055 - accuracy: 0.8459\n",
      "Epoch 43/100\n",
      "27311/27311 [==============================] - 18s 673us/step - loss: 0.4054 - accuracy: 0.8460\n",
      "Epoch 44/100\n",
      "27311/27311 [==============================] - 19s 680us/step - loss: 0.4053 - accuracy: 0.8459\n",
      "Epoch 45/100\n",
      "27311/27311 [==============================] - 19s 713us/step - loss: 0.4054 - accuracy: 0.8459\n",
      "Epoch 46/100\n",
      "27311/27311 [==============================] - 18s 669us/step - loss: 0.4054 - accuracy: 0.8459\n",
      "Epoch 47/100\n",
      "27311/27311 [==============================] - 19s 682us/step - loss: 0.4053 - accuracy: 0.8459\n",
      "Epoch 48/100\n",
      "27311/27311 [==============================] - 18s 669us/step - loss: 0.4052 - accuracy: 0.8459\n",
      "Epoch 49/100\n",
      "27311/27311 [==============================] - 18s 660us/step - loss: 0.4053 - accuracy: 0.8459\n",
      "Epoch 50/100\n",
      "27311/27311 [==============================] - 19s 699us/step - loss: 0.4052 - accuracy: 0.8459\n",
      "Epoch 51/100\n",
      "27311/27311 [==============================] - 18s 672us/step - loss: 0.4052 - accuracy: 0.8459\n",
      "Epoch 52/100\n",
      "27311/27311 [==============================] - 18s 672us/step - loss: 0.4052 - accuracy: 0.8459\n",
      "Epoch 53/100\n",
      "27311/27311 [==============================] - 18s 658us/step - loss: 0.4051 - accuracy: 0.8460\n",
      "Epoch 54/100\n",
      "27311/27311 [==============================] - 18s 666us/step - loss: 0.4051 - accuracy: 0.8460\n",
      "Epoch 55/100\n",
      "27311/27311 [==============================] - 19s 690us/step - loss: 0.4051 - accuracy: 0.8460\n",
      "Epoch 56/100\n",
      "27311/27311 [==============================] - 19s 689us/step - loss: 0.4052 - accuracy: 0.8460\n",
      "Epoch 57/100\n",
      "27311/27311 [==============================] - 19s 694us/step - loss: 0.4050 - accuracy: 0.8460\n",
      "Epoch 58/100\n",
      "27311/27311 [==============================] - 19s 700us/step - loss: 0.4051 - accuracy: 0.8459\n",
      "Epoch 59/100\n",
      "27311/27311 [==============================] - 19s 678us/step - loss: 0.4050 - accuracy: 0.8459\n",
      "Epoch 60/100\n",
      "27311/27311 [==============================] - 18s 677us/step - loss: 0.4050 - accuracy: 0.8460\n",
      "Epoch 61/100\n",
      "27311/27311 [==============================] - 19s 683us/step - loss: 0.4050 - accuracy: 0.8459\n",
      "Epoch 62/100\n",
      "27311/27311 [==============================] - 18s 675us/step - loss: 0.4049 - accuracy: 0.8459\n",
      "Epoch 63/100\n",
      "27311/27311 [==============================] - 19s 709us/step - loss: 0.4049 - accuracy: 0.8460\n",
      "Epoch 64/100\n",
      "27311/27311 [==============================] - 20s 727us/step - loss: 0.4049 - accuracy: 0.8461\n",
      "Epoch 65/100\n",
      "27311/27311 [==============================] - 18s 677us/step - loss: 0.4049 - accuracy: 0.8460\n",
      "Epoch 66/100\n",
      "27311/27311 [==============================] - 18s 670us/step - loss: 0.4050 - accuracy: 0.8460\n",
      "Epoch 67/100\n",
      "27311/27311 [==============================] - 18s 676us/step - loss: 0.4048 - accuracy: 0.8460\n",
      "Epoch 68/100\n",
      "27311/27311 [==============================] - 18s 671us/step - loss: 0.4048 - accuracy: 0.8460\n",
      "Epoch 69/100\n",
      "27311/27311 [==============================] - 19s 678us/step - loss: 0.4048 - accuracy: 0.8460\n",
      "Epoch 70/100\n",
      "27311/27311 [==============================] - 19s 678us/step - loss: 0.4048 - accuracy: 0.8460\n",
      "Epoch 71/100\n",
      "27311/27311 [==============================] - 19s 681us/step - loss: 0.4048 - accuracy: 0.8460\n",
      "Epoch 72/100\n",
      "27311/27311 [==============================] - 19s 682us/step - loss: 0.4048 - accuracy: 0.8461\n",
      "Epoch 73/100\n",
      "27311/27311 [==============================] - 19s 680us/step - loss: 0.4048 - accuracy: 0.8461\n",
      "Epoch 74/100\n",
      "27311/27311 [==============================] - 19s 704us/step - loss: 0.4048 - accuracy: 0.8461\n",
      "Epoch 75/100\n",
      "27311/27311 [==============================] - 19s 703us/step - loss: 0.4048 - accuracy: 0.8460\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27311/27311 [==============================] - 18s 677us/step - loss: 0.4048 - accuracy: 0.8460\n",
      "Epoch 77/100\n",
      "27311/27311 [==============================] - 18s 645us/step - loss: 0.4047 - accuracy: 0.8460\n",
      "Epoch 78/100\n",
      "27311/27311 [==============================] - 16s 599us/step - loss: 0.4047 - accuracy: 0.8461\n",
      "Epoch 79/100\n",
      "27311/27311 [==============================] - 16s 600us/step - loss: 0.4047 - accuracy: 0.8460\n",
      "Epoch 80/100\n",
      "27311/27311 [==============================] - 16s 604us/step - loss: 0.4047 - accuracy: 0.8460\n",
      "Epoch 81/100\n",
      "27311/27311 [==============================] - 16s 600us/step - loss: 0.4046 - accuracy: 0.8461\n",
      "Epoch 82/100\n",
      "27311/27311 [==============================] - 17s 604us/step - loss: 0.4046 - accuracy: 0.8461\n",
      "Epoch 83/100\n",
      "27311/27311 [==============================] - 17s 620us/step - loss: 0.4046 - accuracy: 0.8461\n",
      "Epoch 84/100\n",
      "27311/27311 [==============================] - 16s 600us/step - loss: 0.4046 - accuracy: 0.8461\n",
      "Epoch 85/100\n",
      "27311/27311 [==============================] - 16s 597us/step - loss: 0.4046 - accuracy: 0.8461\n",
      "Epoch 86/100\n",
      "27311/27311 [==============================] - 17s 616us/step - loss: 0.4046 - accuracy: 0.8461\n",
      "Epoch 87/100\n",
      "27311/27311 [==============================] - 17s 627us/step - loss: 0.4046 - accuracy: 0.8461\n",
      "Epoch 88/100\n",
      "27311/27311 [==============================] - 16s 600us/step - loss: 0.4045 - accuracy: 0.8461\n",
      "Epoch 89/100\n",
      "27311/27311 [==============================] - 16s 595us/step - loss: 0.4045 - accuracy: 0.8461\n",
      "Epoch 90/100\n",
      "27311/27311 [==============================] - 16s 604us/step - loss: 0.4045 - accuracy: 0.8461\n",
      "Epoch 91/100\n",
      "27311/27311 [==============================] - 16s 602us/step - loss: 0.4045 - accuracy: 0.8461\n",
      "Epoch 92/100\n",
      "27311/27311 [==============================] - 16s 601us/step - loss: 0.4045 - accuracy: 0.8461\n",
      "Epoch 93/100\n",
      "27311/27311 [==============================] - 16s 599us/step - loss: 0.4044 - accuracy: 0.8461\n",
      "Epoch 94/100\n",
      "27311/27311 [==============================] - 16s 600us/step - loss: 0.4044 - accuracy: 0.8461\n",
      "Epoch 95/100\n",
      "27311/27311 [==============================] - 16s 600us/step - loss: 0.4042 - accuracy: 0.8461\n",
      "Epoch 96/100\n",
      "27311/27311 [==============================] - 16s 598us/step - loss: 0.4041 - accuracy: 0.8461\n",
      "Epoch 97/100\n",
      "27311/27311 [==============================] - 16s 600us/step - loss: 0.4041 - accuracy: 0.8460\n",
      "Epoch 98/100\n",
      "27311/27311 [==============================] - 17s 604us/step - loss: 0.4041 - accuracy: 0.8461\n",
      "Epoch 99/100\n",
      "27311/27311 [==============================] - 16s 601us/step - loss: 0.4040 - accuracy: 0.8461\n",
      "Epoch 100/100\n",
      "27311/27311 [==============================] - 16s 601us/step - loss: 0.4039 - accuracy: 0.8462\n",
      "9104/9104 - 4s - loss: 0.4080 - accuracy: 0.8458\n",
      "Loss: 0.4080069363117218, Accuracy: 0.8458263874053955\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 =  1.5 * len(X_train_scaled[0])\n",
    "hidden_nodes_layer2 = 12\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Predictions\n",
    "y_pred = tf.round(nn.predict(X_test_scaled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92    246370\n",
      "           1       0.52      0.01      0.01     44938\n",
      "\n",
      "    accuracy                           0.85    291308\n",
      "   macro avg       0.68      0.50      0.47    291308\n",
      "weighted avg       0.80      0.85      0.78    291308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[246083,    287],\n",
       "       [ 44625,    313]], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Final Selection\n",
    "After evaluating each model using the entire combined dataset, it was found that Decision Tree was the best at predicting delays.  That will be the model we will use going forward."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
